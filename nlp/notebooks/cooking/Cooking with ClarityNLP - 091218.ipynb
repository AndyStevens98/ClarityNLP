{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooking with ClarityNLP - Session #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this series is to introduce you to writing basic queries using NLPQL.  Today we will also be covering an introduction to data ingestion and tagging.  For other details on installing and using ClarityNLP, please see our [documentation](https://claritynlp.readthedocs.io/en/latest/index.html).  We welcome questions via Slack or on [GitHub](https://github.com/ClarityNLP/ClarityNLP/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run NLP jobs using ClarityNLP, data must first be ingested into the system.  You can ingest data from various sources (eg. flat files, relational databases, APIs, etc) and of various types (eg. txt, doc, pdf, etc). Today we will cover one of the most common ingestion patterns-- bringing in data from a CSV.  ClarityNLP has a user interface to support CSV ingestion.  In a typical instance, this will be located at `localhost:6543/csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[INSERT INGESTION PICTURE HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of ingesting data from CSV involves the following steps:\n",
    "1. Select your CSV file to load column headers\n",
    "2. Assign the required fields for ClarithNLP to columns in your file\n",
    "3. Add any additional fields you would like to include from your source file\n",
    "4. Start the Import process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the ingestion screen filled out for the MIMIC-III notes file (NOTEEVENTS.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert MIMIC Ingestion form picture here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Mapping?? (Save for next time?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Run NLPQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run NLPQL, you must submit it to a ClarityNLP server either via API or via the ClarityNLP user interface.  If you are running a local instance, the API endpoint is typically `localhost:5000/nlpql`.  NLPQL should be POSTed as text/plain.  An example from [Postman](www.postman.com) is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Postman.png](assets/Postman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unfamiliar with using tools such as Postman, you can submit NLPQL via the ClarityNLP user interface running in a web browser. For local instances, this will be at [localhost:8200/runner](localhost:8200/runner). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NLPQL_Runner.png](assets/NLPQL_Runner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to run NLPQL directly from this notebook, then please use the following code.  You will need to edit the `url` variable to \"localhost:5000/\" or your ClarityNLP server IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClarityNLP notebook helpers loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# This code below is only required for running ClarityNLP in Jupyter notebooks. It is not required if running NLPQL via API or the ClarityNLP GUI.\n",
    "\n",
    "import pandas as pd\n",
    "import claritynlp_notebook_helpers as claritynlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: Throughout these tutorials, we will prepend all examples with `limit 100;`.  This limits the server to analyzing a maxium of 100 documents, reducing runtime and compute load when testing new queries. Once a query is producing the expected output, removing this line will allow the full dataset to be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #1:  Prostate Cancer\n",
    "For this first use case, we are going to look at a few different approaches to analyzing prostate cancer.  First we will start with just the basic approach we covered last time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Find mentions of \"Prostate Cancer\" in the patient chart."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We will start with a basic example, simply looking for a positive assertion of \"prostate cancer\" or \"prostate ca\" in the record.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Prostate Cancer\" version \"1\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset ProstateTerms:\n",
    "  [\"prostate cancer\",\"prostate ca\"];\n",
    "\n",
    "define ProstateCA:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[ProstateCA]\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this NLPQL, copy/paste the above and submit via API or the ClarityNLP interface.  Or if you would like to run the NLPQL directoly within this notebook, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://localhost:5000/job_results/10395/phenotype_intermediate\",\n",
      "    \"job_id\": \"10395\",\n",
      "    \"luigi_task_monitoring\": \"http://localhost:8082/static/visualiser/index.html#search__search=job=10395\",\n",
      "    \"main_results_csv\": \"http://localhost:5000/job_results/10395/phenotype\",\n",
      "    \"phenotype_config\": \"http://localhost:5000/phenotype_id/10326\",\n",
      "    \"phenotype_id\": \"10326\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://localhost:5000/pipeline_id/10538\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        10538\n",
      "    ],\n",
      "    \"results_viewer\": \"http://localhost:8200/?job=10395\",\n",
      "    \"status_endpoint\": \"http://localhost:5000/status/10395\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Prostate Cancer\" version \"1\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset ProstateTerms:\n",
    "  [\"prostate cancer\",\"prostate ca\"];\n",
    "\n",
    "define ProstateCA:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[ProstateTerms]\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>end</th>\n",
       "      <th>experiencer</th>\n",
       "      <th>inserted_date</th>\n",
       "      <th>job_id</th>\n",
       "      <th>negation</th>\n",
       "      <th>nlpql_feature</th>\n",
       "      <th>owner</th>\n",
       "      <th>...</th>\n",
       "      <th>report_id</th>\n",
       "      <th>report_type</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>solr_id</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>subject</th>\n",
       "      <th>temporality</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b96beac4606cf403ccca551</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-09-10 14:57:48.859000</td>\n",
       "      <td>10395</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>ProstateCA</td>\n",
       "      <td>claritynlp</td>\n",
       "      <td>...</td>\n",
       "      <td>1129787</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CONDITION</td>\n",
       "      <td>77 year old man w/ prostate CA s/p syncopal ep...</td>\n",
       "      <td>1129787</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>19</td>\n",
       "      <td>27102</td>\n",
       "      <td>Historical</td>\n",
       "      <td>prostate CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b96beac4606cf403ccca552</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>36</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-09-10 14:57:48.867000</td>\n",
       "      <td>10395</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>ProstateCA</td>\n",
       "      <td>claritynlp</td>\n",
       "      <td>...</td>\n",
       "      <td>1129787</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>HISTORY_PRESENT_ILLNESS</td>\n",
       "      <td>77-year-old man with prostate cancer status po...</td>\n",
       "      <td>1129787</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>21</td>\n",
       "      <td>27102</td>\n",
       "      <td>Historical</td>\n",
       "      <td>prostate cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b96beac4606cf403ccca553</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-09-10 14:57:48.973000</td>\n",
       "      <td>10395</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>ProstateCA</td>\n",
       "      <td>claritynlp</td>\n",
       "      <td>...</td>\n",
       "      <td>1051534</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>ADMISSION_DIAGNOSIS</td>\n",
       "      <td>PROSTATE CA/SDA UNDERLYING MEDICAL</td>\n",
       "      <td>1051534</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>99810</td>\n",
       "      <td>Recent</td>\n",
       "      <td>PROSTATE CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5b96beac4606cf403ccca554</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>36</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-09-10 14:57:48.976000</td>\n",
       "      <td>10395</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>ProstateCA</td>\n",
       "      <td>claritynlp</td>\n",
       "      <td>...</td>\n",
       "      <td>1051534</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CONDITION</td>\n",
       "      <td>57 year old man with prostate cancer s/p radic...</td>\n",
       "      <td>1051534</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>21</td>\n",
       "      <td>99810</td>\n",
       "      <td>Historical</td>\n",
       "      <td>prostate cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b96bead4606cf403ccca555</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>36</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2018-09-10 14:57:49.100000</td>\n",
       "      <td>10395</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>ProstateCA</td>\n",
       "      <td>claritynlp</td>\n",
       "      <td>...</td>\n",
       "      <td>1056030</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CONDITION</td>\n",
       "      <td>68 year old man with met prostate ca with sob ...</td>\n",
       "      <td>1056030</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>25</td>\n",
       "      <td>45783</td>\n",
       "      <td>Recent</td>\n",
       "      <td>prostate ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  batch  concept_code  end experiencer  \\\n",
       "0  5b96beac4606cf403ccca551     75            -1   30     Patient   \n",
       "1  5b96beac4606cf403ccca552     75            -1   36     Patient   \n",
       "2  5b96beac4606cf403ccca553     75            -1   11     Patient   \n",
       "3  5b96beac4606cf403ccca554     75            -1   36     Patient   \n",
       "4  5b96bead4606cf403ccca555     75            -1   36     Patient   \n",
       "\n",
       "                inserted_date  job_id  negation nlpql_feature       owner  \\\n",
       "0  2018-09-10 14:57:48.859000   10395  Affirmed    ProstateCA  claritynlp   \n",
       "1  2018-09-10 14:57:48.867000   10395  Affirmed    ProstateCA  claritynlp   \n",
       "2  2018-09-10 14:57:48.973000   10395  Affirmed    ProstateCA  claritynlp   \n",
       "3  2018-09-10 14:57:48.976000   10395  Affirmed    ProstateCA  claritynlp   \n",
       "4  2018-09-10 14:57:49.100000   10395  Affirmed    ProstateCA  claritynlp   \n",
       "\n",
       "        ...         report_id  report_type                  section  \\\n",
       "0       ...           1129787    Radiology                CONDITION   \n",
       "1       ...           1129787    Radiology  HISTORY_PRESENT_ILLNESS   \n",
       "2       ...           1051534    Radiology      ADMISSION_DIAGNOSIS   \n",
       "3       ...           1051534    Radiology                CONDITION   \n",
       "4       ...           1056030    Radiology                CONDITION   \n",
       "\n",
       "                                            sentence  solr_id source start  \\\n",
       "0  77 year old man w/ prostate CA s/p syncopal ep...  1129787  MIMIC    19   \n",
       "1  77-year-old man with prostate cancer status po...  1129787  MIMIC    21   \n",
       "2                 PROSTATE CA/SDA UNDERLYING MEDICAL  1051534  MIMIC     0   \n",
       "3  57 year old man with prostate cancer s/p radic...  1051534  MIMIC    21   \n",
       "4  68 year old man with met prostate ca with sob ...  1056030  MIMIC    25   \n",
       "\n",
       "  subject  temporality             term  \n",
       "0   27102   Historical      prostate CA  \n",
       "1   27102   Historical  prostate cancer  \n",
       "2   99810       Recent      PROSTATE CA  \n",
       "3   99810   Historical  prostate cancer  \n",
       "4   45783       Recent      prostate ca  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_csv_df = pd.read_csv(intermediate_csv)\n",
    "inter_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with Document Sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we don't want to look for mentions of a concept anywhere, but rather only want to look within certain types of documents.  With ClarityNLP, we can extensively control for the types on documents in which we perform any  algorithm.  There are four modifiers that can be used in selecting documents:\n",
    "\n",
    "- report_type\n",
    "- report_tag\n",
    "- filter_query\n",
    "- query\n",
    "\n",
    "***Report Type***\n",
    "\n",
    "When documents are ingested into ClarityNLP, you have the option to assign a report type.  For clinical documents, this is typically something like Discharge Summary, Head CT WWO Contrast, Colonoscopy Report, etc.  Clarity has a convenient function `createReportTypeList` for building a document set based on report type.  Here is an example:\n",
    "\n",
    "```\n",
    "documentset ChestXRayDocuments:\n",
    "   Clarity.createReportTypeList([\"CXR PA/LAT\",\"CXR 2V\",\"AP/LAT CHEST\"]);\n",
    "```\n",
    "\n",
    "***Report Tag***\n",
    "\n",
    "In our research looking at just 10 different health systems, we found thousands of different report types.  Such diversity makes it challenging to create phenotypes that can be applied across diverse settings.  To address this, ClarityNLP embeds a Report Type tagging system that facilitates linking report types to the LOINC / RadLex document ontology.  This enables creation of more standardized NLPQL code.\n",
    "\n",
    "```\n",
    "documentset ChestXRayDocuments:\n",
    "   Clarity.createReportTagList([\"XR\",\"Chest\"]);\n",
    "```\n",
    "\n",
    "***Filter Query***\n",
    "\n",
    "Filter queries are a powerful etc etc Solr documentation.\n",
    "\n",
    "```\n",
    "documentset CXRDocuments:\n",
    "    Clarity.createDocumentSet({\n",
    "        \"report_types\":[],\n",
    "        \"report_tags\": [],\n",
    "        \"filter_query\": \"subject:23224\"});\n",
    "```\n",
    "\n",
    "***Query***\n",
    "\n",
    "Sometimes a highly customized document selection is required and for this we enable use of the full [Solr query language](https://lucene.apache.org/solr/guide/7_4/query-syntax-and-parsing.html).\n",
    "\n",
    "```\n",
    "documentset CXRDocuments:\n",
    "    Clarity.createDocumentSet({\n",
    "        \"report_types\":[],\n",
    "        \"report_tags\": [],\n",
    "        \"query\":\"(french OR fry OR hamburger)\"});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Finding Biopsy Information\n",
    "Let's do a slight addition where we look for mention of biopsy as well as Prostate CA.  First, the simple version where we just look for mention of the word biopsy in the same charts as mention of the word prostate cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example just with adding biopsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Synonyms\n",
    "ClarityNLP has a number of cool built-in features for creating synonyms, plurals, lexical variants and so forth.  Check out the full list of [Termset Expansion](https://clarity-nlp.readthedocs.io/en/latest/user_guide/nlpql/macros.html?highlight=lexical) functions.  Here is an example of an expansion set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```java\n",
    "  phenotype \"Test Expansion Using English Phrases\";\n",
    "\n",
    "  // # Structured Data Model #\n",
    "  datamodel OMOP version \"5.3\";\n",
    "\n",
    "  // # Referenced libraries #\n",
    "  // The ClarityCore library provides common functions for simplifying NLP pipeline creation\n",
    "  include ClarityCore version \"1.0\" called Clarity;\n",
    "  include OHDSIHelpers version \"1.0\" called OHDSI;\n",
    "\n",
    "  // ## Code Systems ##\n",
    "  codesystem OMOP: \"http://omop.org\"; // OMOP vocabulary https://github.com/OHDSI/Vocabulary-v5.0;\n",
    "\n",
    "  termset SynonymTesting: [\n",
    "\n",
    "  // WordNet synonyms for 'prostate'\n",
    "  // Clarity.Synonyms(\"prostate\"),\n",
    "  Clarity.Synonyms(\"prostate\"),\n",
    "\n",
    "\n",
    "  // WordNet synonyms for 'neoplasm'\n",
    "  // Clarity.Synonyms(\"neoplasm\"),\n",
    "  Clarity.Synonyms(\"neoplasm\"),\n",
    "\n",
    "  // Pluralize Synonyms\n",
    "  // Clarity.Plurals(Clarity.Synonyms(\"neoplasm\")),\n",
    "  Clarity.Plurals(Clarity.Synonyms(\"neoplasm\")),\n",
    "\n",
    "  // OHDSI synonyms for 'neoplasm'\n",
    "  // OHDSI.Synonyms(\"neoplasm\"),\n",
    "  OHDSI.Synonyms(\"neoplasm\"),\n",
    "\n",
    "  // OHDSI synonyms for 'myocardial infarction'\n",
    "  // OHDSI.Synonyms(\"myocardial infarction\"),\n",
    "  OHDSI.Synonyms(\"myocardial infarction\"),\n",
    "\n",
    "  //Wordnet synonyms for myocardial infarction\n",
    " //  Clarity.Synonyms(\"myocardial infarction\"),\n",
    "  Clarity.Synonyms(\"myocardial infarction\"),\n",
    "\n",
    "  // Verb inflections for 'biopsy'\n",
    "  // Clarity.VerbInflections(\"biopsy\")\n",
    "  Clarity.VerbInflections(\"biopsy\")\n",
    "\n",
    "  ];\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea],\n",
    "    negated:\"Affirmed\"\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://localhost:5000/job_results/10396/phenotype_intermediate\",\n",
      "    \"job_id\": \"10396\",\n",
      "    \"luigi_task_monitoring\": \"http://localhost:8082/static/visualiser/index.html#search__search=job=10396\",\n",
      "    \"main_results_csv\": \"http://localhost:5000/job_results/10396/phenotype\",\n",
      "    \"phenotype_config\": \"http://localhost:5000/phenotype_id/10327\",\n",
      "    \"phenotype_id\": \"10327\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://localhost:5000/pipeline_id/10539\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        10539\n",
      "    ],\n",
      "    \"results_viewer\": \"http://localhost:8200/?job=10396\",\n",
      "    \"status_endpoint\": \"http://localhost:5000/status/10396\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea],\n",
    "    negated:\"Affirmed\"\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because many term searchers are actually looking for non-negated, non-hypothetical, subject=patient mentions, we provide a convenient function `ProviderAssertion` to capture those mentions without needing to configure TermFinder. \n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Finding Gleason Scores\n",
    "Clues to the aggressiveness of a particular prostate tumor can be obtained from a needle biopsy and examination of the tissue under a microscope. Pathologists have developed a numerical scoring system for classifying the microscopic tissue morphology. This score, called the Gleason score, is an important factor in determining the stage of the cancer and the patient's overall prognosis. In this example we will develop a custom task for extracting Gleason scores.\n",
    "\n",
    "#### 1.3.1 Gleason Score Regular Expressions\n",
    "\n",
    "To develop a custom Gleason score extractor we first need to investigate how these scores are actually reported in medical records. By searching for the term 'Gleason' in a corpus of prostate cancer notes you will find considerable variation:\n",
    "\n",
    "* Gleason score 7\n",
    "* Gleasons score 7 (3+4)\n",
    "* Gleason's score 3 + 4 = 7/10\n",
    "* Gleason pattern of 3+4\n",
    "* Gleasons 5\n",
    "* Gleason five\n",
    "* Gleason's 3 + 3\n",
    "* Gleason grade is 4+\n",
    "* etc.\n",
    "\n",
    "In the first example, the value 7 is the overall score, which consists of the sum of two other components. Sometimes these components are listed in the form i+j, as in the second example, sometimes not. Sometimes only the components are listed and the overall score is omitted, as in the fourth example. Whether listed or not, the value of each component ranges from 1 to 5 inclusive, which means that the total Gleason score has a minimum value of 2 and a maximum value of 10.\n",
    "\n",
    "These forms and others that we observed all fit this generic pattern: \n",
    "\n",
    "1. Gleason text string: `Gleason`, `Gleason's`, `Gleasons`, ...\n",
    "2. (optional) designator text string: `score`, `pattern`, `grade`, possibly followed by \"is\" or \"of\"\n",
    "3. (optional) score, either numeric or text\n",
    "4. (optional) two-part component values, possibly parenthesized\n",
    "\n",
    "A regular expression for recognizing these forms is:\n",
    "\n",
    "```python\n",
    "str_gleason  = r'Gleason(\\'?s)?\\s*'\n",
    "str_desig    = r'(score|sum|grade|pattern)(\\s+(is|of))?'\n",
    "\n",
    "# accept a score in digits under these circumstances:\n",
    "#     digit not followed by a '+', e.g. 'Gleason score 6'\n",
    "#     digit followed by '+' but no digit after, e.g. 'Gleason score 3+'\n",
    "# constructs such as Gleason score 3+3 captured in two-part expression below\n",
    "str_score = r'(?P<score>(\\d+(?!\\+)(?!\\s\\+)|\\d+(?=\\+(?!\\d))|'             +\\\n",
    "            r'two|three|four|five|six|seven|eight|nine|ten))'\n",
    "\n",
    "# parens are optional, space surrounding the '+' varies\n",
    "str_two_part = r'((\\(\\s*)?(?P<first_num>\\d+)\\s*\\+\\s*(?P<second_num>\\d+)' +\\\n",
    "               r'(\\s*\\))?)?'\n",
    "\n",
    "# combine all strings\n",
    "str_total = str_gleason + r'(' + str_desig + r'\\s*)?'                    +\\\n",
    "             r'(' + str_score + r'\\s*)?' + str_two_part\n",
    "             \n",
    "# final Gleason regex\n",
    "regex_gleason = re.compile(str_total, re.IGNORECASE)\n",
    "```\n",
    "\n",
    "Named capture groups are used in the regex to extract the score and each component, if present.\n",
    "\n",
    "#### 1.3.2 Extraction of the Gleason Score from Sentences\n",
    "\n",
    "This regex, along with some additional logic, can be used to recognize and extract Gleason scores from sentences. An outline of the process is:\n",
    "\n",
    "* Attempt a regex match on the current sentence.\n",
    "* If match, extract all named capture groups that exist.\n",
    "* Convert captured values from string to int.\n",
    "* Check captured values and make sure they fall within expected ranges.\n",
    "* If valid, save captured text and values.\n",
    "\n",
    "Our implementation of this logic is in the next code block:\n",
    "\n",
    "```python\n",
    "# convert text scores to integers\n",
    "SCORE_TEXT_TO_INT = {\n",
    "    'two':2,\n",
    "    'three':3,\n",
    "    'four':4,\n",
    "    'five':5,\n",
    "    'six':6,\n",
    "    'seven':7,\n",
    "    'eight':8,\n",
    "    'nine':9,\n",
    "    'ten':10\n",
    "}\n",
    "\n",
    "# namedtuple for result\n",
    "GLEASON_SCORE_RESULT_FIELDS = ['sentence_index', 'start', 'end',\n",
    "                               'score', 'first_num', 'second_num']\n",
    "GleasonScoreResult = namedtuple('GleasonScoreResult', GLEASON_SCORE_RESULT_FIELDS)\n",
    "\n",
    "def find_gleason_score(sentence_list):\n",
    "    \"\"\"\n",
    "    Scan a list of sentences and run Gleason score-finding regexes on each.\n",
    "    Returns a list of GleasonScoreResult namedtuples.\n",
    "    \"\"\"\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for i in range(len(sentence_list)):\n",
    "        s = sentence_list[i]\n",
    "        \n",
    "        # attempt regex match\n",
    "        iterator = regex_gleason.finditer(s)\n",
    "        for match in iterator:\n",
    "            start = match.start()\n",
    "            end   = match.end()\n",
    "\n",
    "            # extract first component if it exists\n",
    "            try:\n",
    "                first_num = int(match.group('first_num'))\n",
    "            except:\n",
    "                first_num = None\n",
    "\n",
    "            # extract second component if it exists\n",
    "            try:\n",
    "                second_num = int(match.group('second_num'))\n",
    "            except:\n",
    "                second_num = None\n",
    "\n",
    "            # extract score if it exists\n",
    "            try:\n",
    "                match_text = match.group('score')\n",
    "                if match_text.isdigit():\n",
    "                    score = int(match_text)\n",
    "                else:\n",
    "                    # convert text score to int\n",
    "                    match_text = match_text.strip()\n",
    "                    if match_text in SCORE_TEXT_TO_INT:\n",
    "                        score = SCORE_TEXT_TO_INT[match_text]\n",
    "                    else:\n",
    "                        score = None\n",
    "            except:\n",
    "                # no single score was given\n",
    "                if first_num is not None and second_num is not None:\n",
    "                    score = first_num + second_num\n",
    "                else:\n",
    "                    score = None\n",
    "\n",
    "            # Now apply these rules to determine if score is valid:\n",
    "            #\n",
    "            #     1 <= first_num <= 5\n",
    "            #     1 <= second_num <= 5\n",
    "            #     2 <= score <= 10\n",
    "            #\n",
    "            # anything outside of these limits is invalid\n",
    "\n",
    "            if first_num is not None and (first_num > 5 and first_num <= 10):\n",
    "                # assume score reported for first_num\n",
    "                score = first_num\n",
    "                first_num = None\n",
    "                second_num = None\n",
    "            elif score is not None and (score < 2 or score > 10):\n",
    "                # invalid\n",
    "                score = None\n",
    "                continue\n",
    "                    \n",
    "            result = GleasonScoreResult(i, start, end, score, first_num, second_num)\n",
    "            result_list.append(result)\n",
    "\n",
    "return result_list\n",
    "```\n",
    "\n",
    "#### 1.3.3 Gleason Score Custom Task for ClarityNLP\n",
    "\n",
    "The code presented above can be combined into a custom task for extracting Gleason scores. Using the custom task framework presented in [Cooking with ClarityNLP Session 1](https://github.com/ClarityNLP/ClarityNLP/blob/master/nlp/notebooks/cooking/Cooking%20with%20ClarityNLP%20-%20082818.ipynb), we hav the following code outline:\n",
    "```python\n",
    "\n",
    "def find_gleason_score(sentence_list):\n",
    "    # see code above\n",
    "\n",
    "class GleasonScoreTask(BaseTask):\n",
    "    \"\"\"\n",
    "    A custom task for finding the Gleason score, which is relevant to \n",
    "    prostate cancer diagnosis and staging.\n",
    "    \"\"\"\n",
    "    \n",
    "    # use this name in NLPQL\n",
    "    task_name = \"GleasonScoreTask\"\n",
    "\n",
    "    def run_custom_task(self, temp_file, mongo_client: MongoClient):\n",
    "\n",
    "        # for each document in the NLPQL-specified doc set\n",
    "        for doc in self.docs:\n",
    "\n",
    "            # all sentences in this document\n",
    "            sentence_list = self.get_document_sentences(doc)\n",
    "\n",
    "            # all Gleason score results in this document\n",
    "            result_list = find_gleason_score(sentence_list)\n",
    "                \n",
    "            if len(result_list) > 0:\n",
    "                for result in result_list:\n",
    "                    obj = {\n",
    "                        'sentence':sentence_list[result.sentence_index],\n",
    "                        'start':result.start,\n",
    "                        'end':result.end,\n",
    "                        'value':result.score,\n",
    "                        'value_first':result.first_num,\n",
    "                        'value_second':result.second_num\n",
    "                    }\n",
    "            \n",
    "self.write_result_data(temp_file, mongo_client, doc, obj)\n",
    "```\n",
    "\n",
    "Each ClarityNLP custom task must be implemented as a derived class of ClarityNLP's `BaseTask` class.  Our custom Gleason score task is called `GleasonScoreTask`, and it is a child of `BaseTask`, as required.\n",
    "\n",
    "The `task_name` field is the name by which this custom task will be invoked from NLPQL. This name is `GleasonScoreTask`.\n",
    "\n",
    "Each custom task must implement the `run_custom_task` function. We do so by iterating over all documents, extracting the document's sentences, and calling our `find_gleason_score` function on each sentence to recognize and extract the Gleason score and its components.\n",
    "\n",
    "If any Gleason scores are found in the document's sentences they are returned as a list of `GleasonScoreResult` namedtuples. We iterate over the list of these tuples and build a python dict that contains the output desired in the phenotype results. The result fields that we write out are:\n",
    "\n",
    "* `sentence`: the sentence containing the Gleason score\n",
    "* `start`: the first character of the text matched by the regex\n",
    "* `end`: one past the last character matched by the regex\n",
    "* `value`: the Gleason score value\n",
    "* `value_first`: the first component of the Gleason score, if any\n",
    "* `value_second`: the second component of the Gleason score, if any\n",
    "\n",
    "In the next cell we present a sample NLPQL program to invoke the custom task and extract Gleason scores. This code uses the `createDocumentSet` function to limit the input documents to those with a `report_type` field equal to `Pathology`. Gleason scores are determined by examining tissue under a microscope, so pathology reports are the expected source of these scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample NLPQL to find Gleason scores from pathology reports\n",
    "nlpql ='''\n",
    "limit 200;\n",
    "\n",
    "phenotype \"Gleason Score Finder\" version \"1\";\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "documentset Docs:\n",
    "    Clarity.createDocumentSet({\n",
    "        \"report_types\":[\"Pathology\"]\n",
    "    });\n",
    "\n",
    "define final GleasonFinderFunction:\n",
    "    Clarity.GleasonScoreTask({\n",
    "        documentset: [Docs]\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Finding Patients with Elevated PSA and Biopsy Findings\n",
    "OHDSI Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ? Social Suport "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will be searching for ejection fraction values using a very simple algorithm.  Specifically, we will be looking for certain terms and subsequent values that would be typical for EF values.  (There are many more sophisticated methods to find ejection fraction (e.g [Kim et al](https://www.ncbi.nlm.nih.gov/pubmed/28163196)).)  We will then constrain the \"final\" cohort to only those with an EF < 30.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"Ejection Fraction Values\" version \"1\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "//logical Context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define final LowEFPatient:\n",
    "    where EjectionFraction.value <= 30;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"Ejection Fraction Values\" version \"1\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "//logical Context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define final LowEFPatient:\n",
    "    where EjectionFraction.value <= 30;\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `final` declaration refers to a cohort definition and typically involves some logic.  So in this case we defined an extraction process to pull all values between 10 and 85 following EF, LVEF, etc.  We then specified a `context`, meaning that the logic should operate on the level of a patient.  (The other option is Document context, which we will describe in a future session.)  Our logical rule stated that patients with an EjectionFraction <= 30 would make our criteria for a Low EF Patient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be found at the main_results_csv URL from your API response, or if  you ran here in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv_df = pd.read_csv(main_csv)\n",
    "final_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use ValueExtraction to pull out an enumerated value set (rather than a quantitative value).  See the example below for NYHA class.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "define NYHAClass:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "define NYHAClass:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view intermediate results\n",
    "inter_csv_df = pd.read_csv(intermediate_csv)\n",
    "inter_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Bringing the criteria together to find the target CHF cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final step in example 1, we want to bring together the above criteria to generate our final cohort.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "//termsets\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "//data extractions\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "\n",
    "define NYHAClass34:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "\n",
    "//logical context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define LowEF:\n",
    "    where EjectionFraction.value <= 30;\n",
    "\n",
    "define SevereCHF:\n",
    "    where NYHAClass34 OR LowEF;\n",
    "    \n",
    "define final SevereCHFwithOrthopnea:\n",
    "    where SevereCHF AND hasOrthopnea;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"Final CHF Cohort\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "//termsets\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "//data extractions\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "\n",
    "define NYHAClass34:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "\n",
    "//logical context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define LowEF:\n",
    "    where EjectionFraction.value <= 30;\n",
    "\n",
    "define SevereCHF:\n",
    "    where NYHAClass34 OR LowEF;\n",
    "    \n",
    "define final SevereCHFwithOrthopnea:\n",
    "    where SevereCHF AND hasOrthopnea;\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv_df = pd.read_csv(main_csv)\n",
    "final_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above case, we may need to increase our limit beyond 100 documents to find many matching patients, because multiple criteria are required and a small sample may not be enough.  Try increasing to 500 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Results through the ClarityNLP UI\n",
    "Downloading the raw CSV results is handy for analysis and data manipulation.  However, a domain-oriented end user may be more interested in just exploring and validating the final results without getting into all the programmatic details.  That's where the Results Viewer comes in, which in a typical installation will be found at localhost:8200/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-08-29%20at%209.33.35%20AM.png](assets/Clarity Validator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #2: Capturing Information on Patient Race\n",
    "Although there are many useful [core algorithms](https://claritynlp.readthedocs.io/en/latest/developer_guide/index.html#task-algorithms) in ClarityNLP, users will frequently want to extend its functionality.  In this second example, we will explore how to extend ClarityNLP when the built in algorithms are inadequate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we'd like to identify the patient's race.  While some version of this could probably we done with simple search terms, a custom algorithm will likely be necessary.  Below is an example of a custom Python algorithm written to extract race information from a document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "str_sep = r'(\\s-\\s|-\\s|\\s-|\\s)'\n",
    "str_word = r'\\b[-a-z.\\d]+'\n",
    "str_punct = r'[,.\\s]*'\n",
    "str_words = r'(' + str_word + str_punct + r'){0,6}'\n",
    "str_person = r'\\b(gentleman|gentlewoman|male|female|man|woman|person|'    +\\\n",
    "             r'child|boy|girl|infant|baby|newborn|neonate|individual)\\b'\n",
    "str_category = r'\\b(american' + str_sep + r'indian|'                      +\\\n",
    "               r'alaska' + str_sep + r'native|asian|'                     +\\\n",
    "               r'african' + str_sep + r'american|black|negro|'            +\\\n",
    "               r'native' + str_sep + r'hawaiian|'                         +\\\n",
    "               r'other' + str_sep + r'pacific' + str_sep + r'islander|'   +\\\n",
    "               r'pacific' + str_sep + r'islander|'                        +\\\n",
    "               r'native' + str_sep + r'american|'                         +\\\n",
    "               r'white|caucasian|european)'\n",
    "\n",
    "str_race1 = r'(\\brace:?\\s*)' + r'(?P<category>' + str_category + r')'\n",
    "regex_race1 = re.compile(str_race1, re.IGNORECASE)\n",
    "str_race2 = r'(?P<category>' + str_category + r')' + str_punct    +\\\n",
    "            str_words + str_person\n",
    "regex_race2 = re.compile(str_race2, re.IGNORECASE)\n",
    "str_race3 = str_person + str_punct + str_words + r'(?P<category>' +\\\n",
    "            str_category + r')'\n",
    "regex_race3 = re.compile(str_race3, re.IGNORECASE)\n",
    "REGEXES = [regex_race1, regex_race2, regex_race3]\n",
    "\n",
    "RACE_FINDER_RESULT_FIELDS = ['sentence_index', 'start', 'end', 'race',\n",
    "                             'normalized_race']\n",
    "RaceFinderResult = namedtuple('RaceFinderResult', RACE_FINDER_RESULT_FIELDS)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "def normalize(race_text):\n",
    "    \"\"\"\n",
    "    Convert a matching race string to a 'normalized' version.\n",
    "    \"\"\"\n",
    "\n",
    "    NORM_MAP = {\n",
    "        'african american':'black',\n",
    "        'negro':'black',\n",
    "        'caucasian':'white',\n",
    "        'european':'white',\n",
    "    }\n",
    "    \n",
    "    # convert to lowercase, remove dashes, collapse repeated whitespace\n",
    "    race = race_text.lower()\n",
    "    race = re.sub(r'[-]+', '', race)\n",
    "    race = re.sub(r'\\s+', ' ', race)\n",
    "\n",
    "    if race in NORM_MAP:\n",
    "        return NORM_MAP[race]\n",
    "    else:\n",
    "        return race\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "def find_race(sentence_list):\n",
    "    \"\"\"\n",
    "    Scan a list of sentences and run race-finding regexes on each.\n",
    "    Return a dict that maps sentence_index -> race_category.\n",
    "    \"\"\"\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    found_match = False\n",
    "    for i in range(len(sentence_list)):\n",
    "        s = sentence_list[i]\n",
    "        for regex in REGEXES:\n",
    "            match = regex.search(s)\n",
    "            if match:\n",
    "                match_text = match.group('category')\n",
    "                start = match.start()\n",
    "                end   = match.end()\n",
    "                normalized = normalize(match_text)\n",
    "                result = RaceFinderResult(i, start, end, match_text, normalized)\n",
    "                result_list.append(result)\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        # Reports are unlikely to have more than one sentence stating the\n",
    "        # patient's race.\n",
    "        if found_match:\n",
    "            break\n",
    "            \n",
    "    return result_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without going into the details, this algorithm parses text to find race information, normalizes it to standard terms, and passes back the result.  In order to run this algorithm using NLPQL in ClarityNLP, we create what is called a custom task.  Below is code that creates the CustomTask wrapping this function and provides it with the documents and handling of result ouput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# use this name in NLPQL\n",
    "    task_name = \"RaceFinderTask\"\n",
    "\n",
    "    def run_custom_task(self, temp_file, mongo_client: MongoClient):\n",
    "\n",
    "        # for each document in the NLPQL-specified doc set\n",
    "        for doc in self.docs:\n",
    "\n",
    "            # all sentences in this document\n",
    "            sentence_list = self.get_document_sentences(doc)\n",
    "\n",
    "            # all race results in this document\n",
    "            result_list = find_race(sentence_list)\n",
    "                \n",
    "            if len(result_list) > 0:\n",
    "                for result in result_list:\n",
    "                    obj = {\n",
    "                        'sentence':sentence_list[result.sentence_index],\n",
    "                        'start':result.start,\n",
    "                        'end':result.end,\n",
    "                        'value':result.race,\n",
    "                        'value_normalized':result.normalized_race,\n",
    "                    }\n",
    "            \n",
    "                    self.write_result_data(temp_file, mongo_client, doc, obj)\n",
    "                    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files can be split into two or can be combined as shown in the final custom task below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymongo import MongoClient\n",
    "from collections import namedtuple\n",
    "from tasks.task_utilities import BaseTask\n",
    "\n",
    "str_sep = r'(\\s-\\s|-\\s|\\s-|\\s)'\n",
    "str_word = r'\\b[-a-z.\\d]+'\n",
    "str_punct = r'[,.\\s]*'\n",
    "str_words = r'(' + str_word + str_punct + r'){0,6}'\n",
    "str_person = r'\\b(gentleman|gentlewoman|male|female|man|woman|person|'    +\\\n",
    "             r'child|boy|girl|infant|baby|newborn|neonate|individual)\\b'\n",
    "str_category = r'\\b(american' + str_sep + r'indian|'                      +\\\n",
    "               r'alaska' + str_sep + r'native|asian|'                     +\\\n",
    "               r'african' + str_sep + r'american|black|negro|'            +\\\n",
    "               r'native' + str_sep + r'hawaiian|'                         +\\\n",
    "               r'other' + str_sep + r'pacific' + str_sep + r'islander|'   +\\\n",
    "               r'pacific' + str_sep + r'islander|'                        +\\\n",
    "               r'native' + str_sep + r'american|'                         +\\\n",
    "               r'white|caucasian|european)'\n",
    "\n",
    "str_race1 = r'(\\brace:?\\s*)' + r'(?P<category>' + str_category + r')'\n",
    "regex_race1 = re.compile(str_race1, re.IGNORECASE)\n",
    "str_race2 = r'(?P<category>' + str_category + r')' + str_punct    +\\\n",
    "            str_words + str_person\n",
    "regex_race2 = re.compile(str_race2, re.IGNORECASE)\n",
    "str_race3 = str_person + str_punct + str_words + r'(?P<category>' +\\\n",
    "            str_category + r')'\n",
    "regex_race3 = re.compile(str_race3, re.IGNORECASE)\n",
    "REGEXES = [regex_race1, regex_race2, regex_race3]\n",
    "\n",
    "RACE_FINDER_RESULT_FIELDS = ['sentence_index', 'start', 'end', 'race',\n",
    "                             'normalized_race']\n",
    "RaceFinderResult = namedtuple('RaceFinderResult', RACE_FINDER_RESULT_FIELDS)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "def normalize(race_text):\n",
    "    \"\"\"\n",
    "    Convert a matching race string to a 'normalized' version.\n",
    "    \"\"\"\n",
    "\n",
    "    NORM_MAP = {\n",
    "        'african american':'black',\n",
    "        'negro':'black',\n",
    "        'caucasian':'white',\n",
    "        'european':'white',\n",
    "    }\n",
    "    \n",
    "    # convert to lowercase, remove dashes, collapse repeated whitespace\n",
    "    race = race_text.lower()\n",
    "    race = re.sub(r'[-]+', '', race)\n",
    "    race = re.sub(r'\\s+', ' ', race)\n",
    "\n",
    "    if race in NORM_MAP:\n",
    "        return NORM_MAP[race]\n",
    "    else:\n",
    "        return race\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "def find_race(sentence_list):\n",
    "    \"\"\"\n",
    "    Scan a list of sentences and run race-finding regexes on each.\n",
    "    Return a dict that maps sentence_index -> race_category.\n",
    "    \"\"\"\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    found_match = False\n",
    "    for i in range(len(sentence_list)):\n",
    "        s = sentence_list[i]\n",
    "        for regex in REGEXES:\n",
    "            match = regex.search(s)\n",
    "            if match:\n",
    "                match_text = match.group('category')\n",
    "                start = match.start()\n",
    "                end   = match.end()\n",
    "                normalized = normalize(match_text)\n",
    "                result = RaceFinderResult(i, start, end, match_text, normalized)\n",
    "                result_list.append(result)\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        # Reports are unlikely to have more than one sentence stating the\n",
    "        # patient's race.\n",
    "        if found_match:\n",
    "            break\n",
    "            \n",
    "    return result_list\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "class RaceFinderTask(BaseTask):\n",
    "    \"\"\"\n",
    "    A custom task for finding a patient's race.\n",
    "    \"\"\"\n",
    "    \n",
    "    # use this name in NLPQL\n",
    "    task_name = \"RaceFinderTask\"\n",
    "\n",
    "    def run_custom_task(self, temp_file, mongo_client: MongoClient):\n",
    "\n",
    "        # for each document in the NLPQL-specified doc set\n",
    "        for doc in self.docs:\n",
    "\n",
    "            # all sentences in this document\n",
    "            sentence_list = self.get_document_sentences(doc)\n",
    "\n",
    "            # all race results in this document\n",
    "            result_list = find_race(sentence_list)\n",
    "                \n",
    "            if len(result_list) > 0:\n",
    "                for result in result_list:\n",
    "                    obj = {\n",
    "                        'sentence':sentence_list[result.sentence_index],\n",
    "                        'start':result.start,\n",
    "                        'end':result.end,\n",
    "                        'value':result.race,\n",
    "                        'value_normalized':result.normalized_race,\n",
    "                    }\n",
    "            \n",
    "                    self.write_result_data(temp_file, mongo_client, doc, obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This race task can be called in NLPQL as follows:\n",
    "\n",
    "```java\n",
    "    limit 100;\n",
    "\n",
    "    phenotype \"Race Finder\" version \"1\";\n",
    "    include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "    documentset DischargeSummaries:\n",
    "        Clarity.createReportTagList([\"Discharge Summary\"]);\n",
    "\n",
    "    define RaceFinderFunction:\n",
    "        Clarity.RaceFinderTask({\n",
    "            documentset: [DischargeSummaries]\n",
    "        });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  This example is our first time using `documentset`, which allows us to specify a targeted list of documents such as Discharge Summaries or Radiology notes etc.  We will cover this is greater detail in future Cooking sessions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpql ='''\n",
    "limit 100;\n",
    "\n",
    "phenotype \"Race Finder\" version \"1\";\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "documentset DischargeSummaries:\n",
    "    Clarity.createReportTagList([\"Discharge Summary\"]);\n",
    "\n",
    "define RaceFinderFunction:\n",
    "    Clarity.RaceFinderTask({\n",
    "        documentset: [DischargeSummaries]\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view intermediate results\n",
    "inter_csv_df = pd.read_csv(intermediate_csv)\n",
    "inter_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Combining race with other criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably gathered, you can now write NLPQL that will look for all patients matching our CHF criteria with the race information extracted above.  The NLPQL would look like this:\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "//termsets\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "\n",
    "//documentsets\n",
    "documentset DischargeSummaries:\n",
    "    Clarity.createReportTagList([\"Discharge Summary\"]);\n",
    "\n",
    "\n",
    "//data extractions\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "\n",
    "define NYHAClass34:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "\n",
    "\n",
    "define Race:\n",
    "    Clarity.RaceFinderTask({\n",
    "        documentset: [DischargeSummaries]\n",
    "    });\n",
    "       \n",
    "\n",
    "//logical context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define LowEF:\n",
    "    where EjectionFraction.value <= 30;\n",
    "\n",
    "define SevereCHF:\n",
    "    where NYHAClass34 OR LowEF;\n",
    "\n",
    "define BlackRace:\n",
    "    where Race.normalized_value = 'black';\n",
    "    \n",
    "define final SevereCHFwithOrthopnea:\n",
    "    where SevereCHF AND hasOrthopnea;\n",
    "\n",
    "define final BlackSevereCHFPatient:\n",
    "    where SevereCHF AND BlackRace;\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
