{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooking with ClarityNLP - Session #7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this [#cookingWithClarityNLP](https://twitter.com/hashtag/cookingWithClarityNLP?src=hash&lang=en) session is to highlight how ClarityNLP can be used to detect, extract, and classify different sub-categories of [adverse events](https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfcfr/cfrsearch.cfm?fr=312.32) from patient-level documents, and/or drug labels. \n",
    "\n",
    "For details on installing and using ClarityNLP, please see our [documentation](https://claritynlp.readthedocs.io/en/latest/index.html).  We welcome questions during this presentation, as well as [via Slack](https://join.slack.com/t/claritynlp/shared_invite/enQtNTE5NTUzNzk4MTk5LTFmNWY1NWVmZTA4Yjc5MDUwNTRhZTBmNTA0MWM0ZDNmYjdlNTAzYmViYzAzMTkwZDkzODA2YTJhYzQ1ZTliZTQ), Twitter (use the hashtag [#cookingWithClarityNLP](https://twitter.com/hashtag/cookingWithClarityNLP?src=hash&lang=en)), or on [GitHub](https://github.com/ClarityNLP/ClarityNLP/issues). **We also encourage suggestions for topics to cover in future cooking sessions!**\n",
    "\n",
    "If you're running ClarityNLP locally via Docker, make sure that the Docker swarm is up and running before following along:\n",
    "- See https://claritynlp.readthedocs.io/en/latest/setup/local-docker.html#running-locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from collections import OrderedDict\n",
    "pd.set_option('display.width',100000)\n",
    "pd.set_option('max_colwidth',4000)\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import textacy\n",
    "\n",
    "FDA_DIR = \"../../../../repos/FDA_AE_challenge_2019\"\n",
    "\n",
    "\n",
    "import claritynlp_notebook_helpers as claritynlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: (loose outline)\n",
    "1. Overview of adverse events (definitions of sub-categories; examples; references); discussion of the subset of AEs we decided to focus on:\n",
    "    - Pre-existing condition or risk factor\n",
    "    - Indication\n",
    "    - Negation\n",
    "    - Pregnancy\n",
    "    - Class effect\n",
    "    - Overdose/withdrawal\n",
    "\n",
    "2. Overview (high-level) of drug label organization/contents/what it means when an adverse event appears on a drug label; the path toward a reported event appearing on a label\n",
    "3. Brief discussion of pre-processing steps taken (parse xml; find/replace medra w/label; ngrams)\n",
    "4. Overview of rule-construction process => frequency analysis; dependency parsing; naive baseline + enhancements; how we set up the structure of the rules engine to be as efficient as possible (e.g., maximize downselection potential, etc.) \n",
    "5. Describe how our rules engine can be run via NLP_as_a_Service, and/or as a custom task in ClarityNLP\n",
    "6. Demonstration (screenshots?) of using chart review to manually validate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview and Background\n",
    "### 1.1 The FDA Adverse Drug Event Evaluation Challenge\n",
    "\n",
    "Our team is currently working on a submission to the [FDA Adverse Drug Event Evaluation Challenge](https://sites.mitre.org/adeeval/). This challenge requires participating teams to ingest a set of drug labels (in XML format), parse these labels to detect and classify adverse events, and output a set of labels indicating the location, class, and associated [MedDRA](https://www.meddra.org/) information for each positive occurrence of an adverse event.\n",
    "\n",
    "Today, we'll break down some of the components of our drug label evaluation strategy to show how you can use components of the ClarityNLP pipeline (specifically, a custom task, and our chart review GUI-based tool) to detect and classify (a subset of) adverse event mentions when they appear in drug labels and/or patient notes. \n",
    "\n",
    "### 1.2 The Challenge Training Dataset\n",
    "The FDA challenge training dataset contains text from 100 drug labels, stored in XML format. Each drug label is mapped to a series of ground-truth labels; for the sake of clarity, we will continue to distinguish between **drug** labels and **ground-truth** labels. Each ground-truth label corresponds to an adverse event associated with the drug in question (though there are several possible ways that this relationship may manifest itself), and contains the following fields:\n",
    "\n",
    "<img src=\"assets/truth_label_screenshot.png\" style=\"height:50px\">\n",
    "\n",
    "\n",
    "### 1.3 Adverse Event Categories\n",
    "There are several reasons that the FDA may consider an adverse event to be (or not be) of interest to the Office of Surveillance and Epidemiology (OSE). The unique set of reasons, along with their definitions and counts within the FDA training dataset, appear in the table that is generated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels_df(fda_dir=FDA_DIR):\n",
    "    \n",
    "    '''\n",
    "\n",
    "    This function lets us read in the 100 drug label XML files, and parse the XML so that we get each ground \n",
    "    truth label associated with a given drug as a row in our dataframe. We can use this dataframe to get counts \n",
    "    by label.\n",
    "\n",
    "    '''\n",
    "\n",
    "    if not os.path.exists(\"{}/analyze_labels/data/labels_dataframe.csv\".format(fda_dir)):\n",
    "\n",
    "        labels_df = pd.DataFrame(columns = [\"file\", \"len\", \"id\", \"reason\", \"section\", \"start\", \"type\", \"meddra_llt\", \"meddra_llt_id\", \"meddra_pt\", \"meddra_pt_id\"])\n",
    "        counter = 0\n",
    "\n",
    "        for f in os.listdir('{}/ose_xml_training_20181101/'.format(fda_dir)):\n",
    "\n",
    "            drug_name = f.split(\".xml\")[0]\n",
    "\n",
    "            root = xml.etree.ElementTree.parse(\"../ose_xml_training_20181101/{}\".format(f)).getroot()\n",
    "\n",
    "            for child in root:\n",
    "\n",
    "                if child.tag == \"Mentions\":\n",
    "                    for subchild in child:\n",
    "                        if subchild.tag == \"Mention\": \n",
    "                            new_row = {}\n",
    "\n",
    "                            new_row[\"file\"] = drug_name.lower() \n",
    "                            new_row = {**new_row, **subchild.attrib}\n",
    "\n",
    "                            for subsubchild  in subchild:\n",
    "\n",
    "                                if subsubchild.tag == \"Normalization\":                    \n",
    "                                      new_row = {**new_row, **subsubchild.attrib}\n",
    "\n",
    "                        temp_df = pd.DataFrame.from_dict(new_row, orient='index').T\n",
    "\n",
    "                        labels_df.loc[counter, :] = temp_df.loc[0,:]\n",
    "                        counter += 1\n",
    "                        \n",
    "    else: \n",
    "        labels_df = pd.read_csv(\"{}/analyze_labels/data/labels_dataframe.csv\".format(fda_dir), header=0, index_col=0)\n",
    " \n",
    "    reason_info = pd.read_csv(\"./data/ae_reason_info.csv\", header=0)\n",
    "    \n",
    "    outdf = pd.merge(labels_df, reason_info, left_on=[\"reason\", \"type\"], right_on=[\"reason\", \"type\"])\n",
    "        \n",
    "    return outdf.loc[:, [\"file\", \"len\", \"reason\", \"type\", \"meddra_llt\", \"meddra_pt\", \"meddra_pt_id\", \"description\"]]\n",
    "\n",
    "\n",
    "labels_and_info = generate_labels_df(fda_dir=\"../../../../repos/FDA_AE_challenge_2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>reason</th>\n",
       "      <th>description</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>AE_only_as_instruction</td>\n",
       "      <td>AES mentioned in instructions are often mentioned in a hypothetical context, with instructions for what to do if they develop. These AES are not of interest.</td>\n",
       "      <td>3384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>general_term</td>\n",
       "      <td>General terms or non-specific text such as broad categories (e.g., MedDRA system organ class) used to introdue AEs or text describe an outcome (e.g., death) rather than an AE. These are not of interest.</td>\n",
       "      <td>2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Not_AE_Candidate</td>\n",
       "      <td>indication</td>\n",
       "      <td>A clinical symptom or circumstance for which the use of the drug of interest would be appropriate. These mentions are not AEs.</td>\n",
       "      <td>1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>manifestation_or_complication</td>\n",
       "      <td>Text describing signs, symptoms, or changes in lab resuts related to the manifestations of an AE and the sequelae of an AE are not of interest.</td>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>AE_from_drug_interaction</td>\n",
       "      <td>AEs that result from drug-drug interaction or co-administration are not of interest.</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>AE_rate_lteq_placebo</td>\n",
       "      <td>Aes with incidence rate equal to or lower than placebo are not of interest.</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>negation</td>\n",
       "      <td>AE whose presence or occurrence is negated or denied. These AEs are not of interst.</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>AE_animal</td>\n",
       "      <td>AEs observed in animal data are not of interest.</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>OD_or_withdrawal</td>\n",
       "      <td>AE associated with discontinuing a medication or taking more than the prescribed amount. Drug overdoes and withdrawal do not generally occur when a drug is used as indicated. Additionally, in the context of pharmacovigilance, identifying AEs associated with the drug when used as indicated is the highest priority. These AEs are not of interest.</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>AE_from_off_label</td>\n",
       "      <td>AES associated with off-label or unapproved drug use are not of interest.</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Not_AE_Candidate</td>\n",
       "      <td>contraindication</td>\n",
       "      <td>A clinical symptom, circumstance, or condition for which the use of the drug of interest would be inappropriate. These mentions are not AEs.</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>AE_for_another_drug_in_class</td>\n",
       "      <td>AE is related to a class effect but the label specifically states that the AE has not been reported or associated with the drug of interest or that the AE was only reported in another drug in the class to which the drug of interest belongs. These Aes are not of interest.</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Not_AE_Candidate</td>\n",
       "      <td>other</td>\n",
       "      <td>A reason other than the specific reasons listed that the mention is not actually an AE.</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NonOSE_AE</td>\n",
       "      <td>other</td>\n",
       "      <td>A reason for disinterest other than the specific reasons listed.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                type                         reason                                                                                                                                                                                                                                                                                                                                                description  counts\n",
       "4          NonOSE_AE         AE_only_as_instruction                                                                                                                                                                                              AES mentioned in instructions are often mentioned in a hypothetical context, with instructions for what to do if they develop. These AES are not of interest.    3384\n",
       "7          NonOSE_AE                   general_term                                                                                                                                                 General terms or non-specific text such as broad categories (e.g., MedDRA system organ class) used to introdue AEs or text describe an outcome (e.g., death) rather than an AE. These are not of interest.    2122\n",
       "12  Not_AE_Candidate                     indication                                                                                                                                                                                                                             A clinical symptom or circumstance for which the use of the drug of interest would be appropriate. These mentions are not AEs.    1434\n",
       "8          NonOSE_AE  manifestation_or_complication                                                                                                                                                                                                            Text describing signs, symptoms, or changes in lab resuts related to the manifestations of an AE and the sequelae of an AE are not of interest.    1144\n",
       "2          NonOSE_AE       AE_from_drug_interaction                                                                                                                                                                                                                                                                       AEs that result from drug-drug interaction or co-administration are not of interest.     328\n",
       "5          NonOSE_AE           AE_rate_lteq_placebo                                                                                                                                                                                                                                                                                Aes with incidence rate equal to or lower than placebo are not of interest.     306\n",
       "9          NonOSE_AE                       negation                                                                                                                                                                                                                                                                        AE whose presence or occurrence is negated or denied. These AEs are not of interst.     245\n",
       "0          NonOSE_AE                      AE_animal                                                                                                                                                                                                                                                                                                           AEs observed in animal data are not of interest.     241\n",
       "6          NonOSE_AE               OD_or_withdrawal  AE associated with discontinuing a medication or taking more than the prescribed amount. Drug overdoes and withdrawal do not generally occur when a drug is used as indicated. Additionally, in the context of pharmacovigilance, identifying AEs associated with the drug when used as indicated is the highest priority. These AEs are not of interest.     206\n",
       "3          NonOSE_AE              AE_from_off_label                                                                                                                                                                                                                                                                                  AES associated with off-label or unapproved drug use are not of interest.      87\n",
       "11  Not_AE_Candidate               contraindication                                                                                                                                                                                                              A clinical symptom, circumstance, or condition for which the use of the drug of interest would be inappropriate. These mentions are not AEs.       61\n",
       "1          NonOSE_AE   AE_for_another_drug_in_class                                                                            AE is related to a class effect but the label specifically states that the AE has not been reported or associated with the drug of interest or that the AE was only reported in another drug in the class to which the drug of interest belongs. These Aes are not of interest.      55\n",
       "13  Not_AE_Candidate                          other                                                                                                                                                                                                                                                                    A reason other than the specific reasons listed that the mention is not actually an AE.      19\n",
       "10         NonOSE_AE                          other                                                                                                                                                                                                                                                                                           A reason for disinterest other than the specific reasons listed.       6"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason_counts = pd.DataFrame(labels_and_info.groupby(['type','reason', 'description'])['type','reason', 'description'].size().reset_index(name='counts')).sort_values(['counts'], ascending=False)\n",
    "reason_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Our Selected Subset of Adverse Event Categories\n",
    "Looking at the table above, it's clear that the majority of labeled adverse events fall into a few categories: specifically: (1) adverse events that are mentioned in the instructions in a hypothetical context; (2) general terms, which are too broad to be useful; (3) indications (e.g., clinical symptom(s) for which using the drug in question would be appropriate; and (4) complications, which might occur as the result of an AE, but are not adverse events per se.\n",
    "\n",
    "For the purpose of today's discussion, we've decided to focus on on detecting mentions of three different buckets of adverse events; note some of these buckets contain multiple \"reasons\" as defined in the FDA ground truth labels. \n",
    "\n",
    "1. Indication; Contraindication; Risk factor\n",
    "2. Withdrawal; Pregnancy*\n",
    "3. Negation\n",
    "\n",
    "\\* Not: in the FDA training dataset, **Pregnancy** is a medDRA term which appears in the **meddra_llt** field, and co-occurs with multiple grouth-truth reasons. The reason that is of interest here is **contraindication** (e.g., drugs that are contraindicated for women who are pregnant, nursing, or may become pregnant in the near term). For example:\n",
    "\n",
    "<img src=\"assets/pregnancy_contraindication_ex.png\" style=\"height:70px\">\n",
    "\n",
    "## 2. Implementation\n",
    "\n",
    "### 2.1 Generation of Sentence-Level Labels\n",
    "In order to build a rules-based model for detecting/classifying sentences with respect to ground-truth labels, we must first make the provided XML labels into a sentence-level feature matrix that can be used to assess model performance on sentences that do and do not contain each of our ground-truth labels. \n",
    "\n",
    "Our first step in this direction was to parse the original XML drug label documents, find the adverse events within the text (using the section-level offsets provided as part of the ground-truth labels), and replace each adverse event with the concatenation of the \"type\"||\"reason\" fields. This will allow us to identify patterns at a more generic level (since we'll be working with the finite set of {\"type\"||\"reasons\"} rather than the more specific set of underlying adverse events, which are linked to medDRA terms within the ground-truth labels. \n",
    "\n",
    "The functions that appear below represent the next step in the process, and serve to generate a sentence-level feature matrix, such that each sentence in each drug label document represents a row, and each possible \"type\"||\"reason\" ground-truth label represents a Boolean-valued column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_type_reason_combos(reason_counts_df):\n",
    "    \n",
    "    out = OrderedDict()\n",
    "    \n",
    "    for i, row in reason_counts.iterrows():\n",
    "        out[i] = {\"type\": row['type'], \n",
    "                  \"reason\": row['reason'], \n",
    "                  \"combo_term\":'{}{}'.format(row['type'].replace(\"_\", \"\").lower(), row['reason'].replace(\"_\", \"\").lower())}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_matrix(reasons, txt_file_dir=\"{}/ose_txt_training_20181101_type_and_reasons/\".format(FDA_DIR)):\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    \n",
    "    # To generate sentence-level labels, we need to find sentences where the reason-labels we inserted occur    \n",
    "    patterns = [{\"ORTH\": r['combo_term']} for r in reasons.values()]\n",
    "    \n",
    "    for p in patterns:\n",
    "        matcher.add(p['ORTH'], None, [(p)])\n",
    "        \n",
    "    cols = [\"file\", \"sent_id\", \"sent_start\", \"sent_end\", \"sentence\"]\n",
    "    cols += [r['combo_term'] for r in reasons.values()]\n",
    "        \n",
    "    out_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for f in os.listdir(txt_file_dir):\n",
    "            \n",
    "        with open (\"{}{}\".format(txt_file_dir, f), \"r\") as myfile:\n",
    "            \n",
    "            drug_name = f.split(\"_\")[0]\n",
    "            #print(drug_name)\n",
    "\n",
    "            lines = myfile.readlines()\n",
    "            doc = nlp(u'{}'.format(lines))\n",
    "\n",
    "            feature_matrix = pd.DataFrame(index=np.arange(len(list(doc.sents))), columns=cols)\n",
    "\n",
    "            feature_matrix.loc[:, \"file\"] = drug_name.lower()\n",
    "            feature_matrix.loc[:, \"sent_id\"] = [i for i in range(len(list(doc.sents)))]\n",
    "            feature_matrix.loc[:, \"sent_start\"] = [i.start for i in (list(doc.sents))]\n",
    "            feature_matrix.loc[:, \"sent_end\"] = [i.end for i in (list(doc.sents))]\n",
    "            feature_matrix.loc[:, \"sentence\"] = [i for i in (list(doc.sents))]\n",
    "\n",
    "            for r in reasons.values():\n",
    "                feature_matrix.loc[:, r[\"combo_term\"]] = 0\n",
    "\n",
    "            matches = matcher(doc)\n",
    "\n",
    "            for match_id, start, end in matches:\n",
    "\n",
    "                span = doc[start:end]  # the matched span\n",
    "\n",
    "                string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "\n",
    "                match_sent_start = span.sent.start # the start (offset) of the sentence in which the match occurrs\n",
    "                match_sent_end  = span.sent.end # the end (offset) of the sentence in which the match occurrs\n",
    "\n",
    "                match_sent_id = feature_matrix.loc[(feature_matrix['sent_start'] == int(match_sent_start)) &\n",
    "                                                   (feature_matrix['sent_end'] == int(match_sent_end)), \"sent_id\"].values[0]\n",
    "\n",
    "                feature_matrix.loc[match_sent_id, string_id] = 1\n",
    "\n",
    "            if out_df.empty:\n",
    "                out_df = feature_matrix\n",
    "            else:\n",
    "                out_df = out_df.append(feature_matrix)\n",
    "        \n",
    "    out_df.to_csv(\"./data/feature_matrix.csv\")\n",
    "    print(\"Sentence-level feature matrix saved.\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-level feature matrix saved.\n"
     ]
    }
   ],
   "source": [
    "reasons = generate_type_reason_combos(reason_counts)\n",
    "generate_feature_matrix(reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_mat = pd.read_csv(\"./data/feature_matrix.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent_start</th>\n",
       "      <th>sent_end</th>\n",
       "      <th>nonoseaeaeonlyasinstruction</th>\n",
       "      <th>nonoseaegeneralterm</th>\n",
       "      <th>notaecandidateindication</th>\n",
       "      <th>nonoseaemanifestationorcomplication</th>\n",
       "      <th>nonoseaeaefromdruginteraction</th>\n",
       "      <th>nonoseaeaeratelteqplacebo</th>\n",
       "      <th>nonoseaenegation</th>\n",
       "      <th>nonoseaeaeanimal</th>\n",
       "      <th>nonoseaeodorwithdrawal</th>\n",
       "      <th>nonoseaeaefromofflabel</th>\n",
       "      <th>notaecandidatecontraindication</th>\n",
       "      <th>nonoseaeaeforanotherdruginclass</th>\n",
       "      <th>notaecandidateother</th>\n",
       "      <th>nonoseaeother</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.00000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "      <td>16643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>125.002764</td>\n",
       "      <td>3464.641351</td>\n",
       "      <td>3496.045064</td>\n",
       "      <td>0.108334</td>\n",
       "      <td>0.103287</td>\n",
       "      <td>0.057622</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.011176</td>\n",
       "      <td>0.00691</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>106.060032</td>\n",
       "      <td>3100.625173</td>\n",
       "      <td>3104.691473</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.304342</td>\n",
       "      <td>0.233034</td>\n",
       "      <td>0.130408</td>\n",
       "      <td>0.106514</td>\n",
       "      <td>0.094510</td>\n",
       "      <td>0.105127</td>\n",
       "      <td>0.08284</td>\n",
       "      <td>0.050766</td>\n",
       "      <td>0.053628</td>\n",
       "      <td>0.050766</td>\n",
       "      <td>0.042420</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.018984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>1248.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>2539.000000</td>\n",
       "      <td>2571.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>4667.500000</td>\n",
       "      <td>4697.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>582.000000</td>\n",
       "      <td>18339.000000</td>\n",
       "      <td>18366.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sent_id    sent_start      sent_end  nonoseaeaeonlyasinstruction  nonoseaegeneralterm  notaecandidateindication  nonoseaemanifestationorcomplication  nonoseaeaefromdruginteraction  nonoseaeaeratelteqplacebo  nonoseaenegation  nonoseaeaeanimal  nonoseaeodorwithdrawal  nonoseaeaefromofflabel  notaecandidatecontraindication  nonoseaeaeforanotherdruginclass  notaecandidateother  nonoseaeother\n",
       "count  16643.000000  16643.000000  16643.000000                 16643.000000         16643.000000              16643.000000                         16643.000000                   16643.000000               16643.000000      16643.000000       16643.00000            16643.000000            16643.000000                    16643.000000                     16643.000000         16643.000000   16643.000000\n",
       "mean     125.002764   3464.641351   3496.045064                     0.108334             0.103287                  0.057622                             0.017305                       0.011476                   0.009013          0.011176           0.00691                0.002584                0.002884                        0.002584                         0.001803             0.000901       0.000361\n",
       "std      106.060032   3100.625173   3104.691473                     0.310811             0.304342                  0.233034                             0.130408                       0.106514                   0.094510          0.105127           0.08284                0.050766                0.053628                        0.050766                         0.042420             0.030009       0.018984\n",
       "min        0.000000      0.000000      5.000000                     0.000000             0.000000                  0.000000                             0.000000                       0.000000                   0.000000          0.000000           0.00000                0.000000                0.000000                        0.000000                         0.000000             0.000000       0.000000\n",
       "25%       44.000000   1248.000000   1275.000000                     0.000000             0.000000                  0.000000                             0.000000                       0.000000                   0.000000          0.000000           0.00000                0.000000                0.000000                        0.000000                         0.000000             0.000000       0.000000\n",
       "50%       96.000000   2539.000000   2571.000000                     0.000000             0.000000                  0.000000                             0.000000                       0.000000                   0.000000          0.000000           0.00000                0.000000                0.000000                        0.000000                         0.000000             0.000000       0.000000\n",
       "75%      178.000000   4667.500000   4697.000000                     0.000000             0.000000                  0.000000                             0.000000                       0.000000                   0.000000          0.000000           0.00000                0.000000                0.000000                        0.000000                         0.000000             0.000000       0.000000\n",
       "max      582.000000  18339.000000  18366.000000                     1.000000             1.000000                  1.000000                             1.000000                       1.000000                   1.000000          1.000000           1.00000                1.000000                1.000000                        1.000000                         1.000000             1.000000       1.000000"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_mat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Human-in-the-Loop Review and Rule Generation\n",
    "\n",
    "Our next objective is to review the sentences that are positive instances of the subset of the ground-truth labels that we are interested in, using a combination of tools, including manual review, n-gram frequency analysis, dependency parsing, topic modeling, and embeddings. Our hope is that these tools can help us to discover latent pattern(s) that we can use to develop a sentence-level Boolean classifier that will offer improved performance and efficiency relative to the status quo. We've divided up this part so that each ground-truth label gets its own subsection, as some of the rules we'll develop are label-specific. \n",
    "\n",
    "To start, let's define a few helper functions that we can use for each bucket:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_feature_matrix(list_of_reasons, f_matrix, keep_only_true=True):\n",
    "    \n",
    "    cols = [\"file\", \"sent_id\", \"sent_start\", \"sent_end\", \"sentence\"]\n",
    "    cols += list_of_reasons\n",
    "\n",
    "    # For initial review, it can be helpful to only review the positive instances\n",
    "    if keep_only_true:\n",
    "        \n",
    "        subset_df = f_matrix.loc[:, cols]\n",
    "        subset_df['row_sum'] = f_matrix.loc[:, list_of_reasons].sum(axis=1)  \n",
    "        \n",
    "        return subset_df[subset_df[\"row_sum\"] >= 1]\n",
    "    \n",
    "    # But it's important not to forget the sentences w/ FALSE values for the subset of labels we've specified \n",
    "    else:\n",
    "        return f_matrix.loc[:, [cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bucket A: Indication; Contraindication; Risk factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 8)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_a = [\"notaecandidateindication\", \"notaecandidatecontraindication\"] # TODO: find label for risk factor \n",
    "subdf_a = filter_feature_matrix(labels_a, feat_mat, keep_only_true=True)\n",
    "subdf_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bucket B: Withdrawal; Pregnancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 8)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to consider contraindication here again because pregnancy mentions show up under that type_reason. \n",
    "labels_b = [\"notaecandidatecontraindication\", \"nonoseaeodorwithdrawal\"] \n",
    "subdf_b = filter_feature_matrix(labels_b, feat_mat, keep_only_true=True)\n",
    "subdf_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bucket C: Negation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 7)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_c = [\"nonoseaenegation\"]\n",
    "subdf_c = filter_feature_matrix(labels_c, feat_mat, keep_only_true=True)\n",
    "subdf_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health_nlp_py35",
   "language": "python",
   "name": "health_nlp_py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
