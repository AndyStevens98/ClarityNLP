{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooking with ClarityNLP - Session #1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this session is to introduce you to writing basic queries using NLPQL.  For details on installing ClarityNLP, loading data, and tagging document types, please see our [documentation](https://claritynlp.readthedocs.io/en/latest/index.html).  We welcome questions via Slack or on [GitHub](https://github.com/ClarityNLP/ClarityNLP/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Run NLPQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run NLPQL, you must submit it to a ClarityNLP server either via API or via the ClarityNLP user interface.  If you are running a local instance, the API endpoint is typically `localhost:5000/nlpql`.  NLPQL should be POSTed as text/plain.  An example from [Postman](www.postman.com) is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Postman.png](assets/Postman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unfamiliar with using tools such as Postman, you can submit NLPQL via the ClarityNLP user interface running in a web browser. For local instances, this will be at [localhost:8200/runner](localhost:8200/runner). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NLPQL_Runner.png](assets/NLPQL_Runner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to run NLPQL directly from this notebook, then please use the following code.  You will need to edit the `url` variable to \"localhost:5000/\" or your ClarityNLP server IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClarityNLP notebook helpers loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# This code below is only required for running ClarityNLP in Jupyter notebooks. It is not required if running NLPQL via API or the ClarityNLP GUI.\n",
    "\n",
    "import pandas as pd\n",
    "import claritynlp_notebook_helpers as claritynlp\n",
    "from sys import path\n",
    "from os import getcwd\n",
    "\n",
    "dependencies_path = getcwd()[:-17] + 'nlp/'\n",
    "path.insert(1, dependencies_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: Throughout these tutorials, we will prepend all examples with `limit 100;`.  This limits the server to analyzing a maxium of 100 documents, reducing runtime and compute load when testing new queries. Once a query is producing the expected output, removing this line will allow the full dataset to be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #1: Congestive Heart Failure\n",
    "For this first use case, our goal is to find patients with reduced ejection fraction and/or late stage CHF who are experiencing symptomatic orthopnea.  We will begin by breaking this into smaller components then combining into a comprehensive phenotype definition that can be shared across sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Find mentions of \"Orthopnea\" in the patient chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a basic example, simply looking for the presence of a given term in the record.\n",
    "```java\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this NLPQL, copy/paste the above and submit via API or the ClarityNLP interface.  Or if you would like to run the NLPQL directoly within this notebook, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://localhost:5000/job_results/152/phenotype_intermediate\",\n",
      "    \"job_id\": \"152\",\n",
      "    \"luigi_task_monitoring\": \"http://localhost:8082/static/visualiser/index.html#search__search=job=152\",\n",
      "    \"main_results_csv\": \"http://localhost:5000/job_results/152/phenotype\",\n",
      "    \"phenotype_config\": \"http://localhost:5000/phenotype_id/152\",\n",
      "    \"phenotype_id\": \"152\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://localhost:5000/pipeline_id/177\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        177\n",
      "    ],\n",
      "    \"status_endpoint\": \"http://localhost:5000/status/152\"\n",
      "}\n",
      "Job in progress.....\n",
      "Job successfully completed!\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 10;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small jobs with limits such as that above typically take less than 60 seconds to run.  Bigger jobs can take much (much) longer.  You can view your job's progress and see how ClarityNLP has broken up the query using the [Luigi Status Monitor](http://18.220.133.76:8082/static/visualiser/index.html) (see below if the link does not work).  Here is a screenshot of the above query running in Luigi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-08-28%20at%2010.27.36%20PM.png](assets/Luigi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above link for the Luigi task monitor does not work, and you submitted the job using this notebook, then you can run the code block below to get the link for the Luigi task monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8082/static/visualiser/index.html#search__search=job=152\n"
     ]
    }
   ],
   "source": [
    "print(luigi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Results\n",
    "There are two types of results from an NLPQL query: intermediate results and final results.  *Intermediate results* refer to all data that are extracted by the query.  *Final results* refer to only those patients or documents meeting a specified logic (eg. cohort criteria).  \n",
    "\n",
    "For the current task, we have not defined a cohort logic.  We asked only to find mentions of orthopnea, which is a data extraction task and will produce only intermediate results.  To download the intermediate results, you can navigate to the `intermediate_results_csv` URL returned by your API call or if you used this notebook, you can see tne URL and a preview below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:5000/job_results/152/phenotype_intermediate\n"
     ]
    }
   ],
   "source": [
    "print(intermediate_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>concept_code_system</th>\n",
       "      <th>display_name</th>\n",
       "      <th>end</th>\n",
       "      <th>experiencer</th>\n",
       "      <th>inserted_date</th>\n",
       "      <th>job_id</th>\n",
       "      <th>negation</th>\n",
       "      <th>...</th>\n",
       "      <th>report_type</th>\n",
       "      <th>result_display</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>solr_id</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>subject</th>\n",
       "      <th>temporality</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6227785948b11a9eeeb5e509</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>67</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2022-03-08 10:38:01.474000</td>\n",
       "      <td>152</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>...</td>\n",
       "      <td>Journal Abstract</td>\n",
       "      <td>{'date': '2010-03-01T00:00:00Z', 'result_conte...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Approximately 4 hours after cesarean section, ...</td>\n",
       "      <td>pmid_20434111</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>58</td>\n",
       "      <td>Acta anaesthesiologica Taiwanica : official jo...</td>\n",
       "      <td>Recent</td>\n",
       "      <td>orthopnea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6227785948b11a9eeeb5e50a</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>86</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2022-03-08 10:38:01.477000</td>\n",
       "      <td>152</td>\n",
       "      <td>Negated</td>\n",
       "      <td>...</td>\n",
       "      <td>Journal Abstract</td>\n",
       "      <td>{'date': '2010-03-01T00:00:00Z', 'result_conte...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>This case illustrates that we should bear in m...</td>\n",
       "      <td>pmid_20434111</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>77</td>\n",
       "      <td>Acta anaesthesiologica Taiwanica : official jo...</td>\n",
       "      <td>Recent</td>\n",
       "      <td>orthopnea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6227785948b11a9eeeb5e50b</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>138</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2022-03-08 10:38:01.533000</td>\n",
       "      <td>152</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>...</td>\n",
       "      <td>Journal Abstract</td>\n",
       "      <td>{'date': '2016-01-01T00:00:00Z', 'result_conte...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>A 26-year-old white woman diagnosed with syste...</td>\n",
       "      <td>pmid_26757303</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>129</td>\n",
       "      <td>Chest</td>\n",
       "      <td>Recent</td>\n",
       "      <td>orthopnea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6227785948b11a9eeeb5e50c</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>83</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2022-03-08 10:38:01.535000</td>\n",
       "      <td>152</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>...</td>\n",
       "      <td>Journal Abstract</td>\n",
       "      <td>{'date': '2016-01-01T00:00:00Z', 'result_conte...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Three months later, she presented to our clini...</td>\n",
       "      <td>pmid_26757303</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>74</td>\n",
       "      <td>Chest</td>\n",
       "      <td>Recent</td>\n",
       "      <td>orthopnea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6227785948b11a9eeeb5e50d</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hasOrthopnea</td>\n",
       "      <td>86</td>\n",
       "      <td>Patient</td>\n",
       "      <td>2022-03-08 10:38:01.598000</td>\n",
       "      <td>152</td>\n",
       "      <td>Affirmed</td>\n",
       "      <td>...</td>\n",
       "      <td>Journal Abstract</td>\n",
       "      <td>{'date': '2003-12-12T00:00:00Z', 'result_conte...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>A 63-year-old woman was admitted with diffuse ...</td>\n",
       "      <td>pmid_14673740</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>77</td>\n",
       "      <td>Deutsche medizinische Wochenschrift (1946)</td>\n",
       "      <td>Recent</td>\n",
       "      <td>orthopnea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  batch  concept_code  concept_code_system  \\\n",
       "0  6227785948b11a9eeeb5e509     10           NaN                  NaN   \n",
       "1  6227785948b11a9eeeb5e50a     10           NaN                  NaN   \n",
       "2  6227785948b11a9eeeb5e50b     10           NaN                  NaN   \n",
       "3  6227785948b11a9eeeb5e50c     10           NaN                  NaN   \n",
       "4  6227785948b11a9eeeb5e50d     10           NaN                  NaN   \n",
       "\n",
       "   display_name  end experiencer               inserted_date  job_id  \\\n",
       "0  hasOrthopnea   67     Patient  2022-03-08 10:38:01.474000     152   \n",
       "1  hasOrthopnea   86     Patient  2022-03-08 10:38:01.477000     152   \n",
       "2  hasOrthopnea  138     Patient  2022-03-08 10:38:01.533000     152   \n",
       "3  hasOrthopnea   83     Patient  2022-03-08 10:38:01.535000     152   \n",
       "4  hasOrthopnea   86     Patient  2022-03-08 10:38:01.598000     152   \n",
       "\n",
       "   negation    ...           report_type  \\\n",
       "0  Affirmed    ...      Journal Abstract   \n",
       "1   Negated    ...      Journal Abstract   \n",
       "2  Affirmed    ...      Journal Abstract   \n",
       "3  Affirmed    ...      Journal Abstract   \n",
       "4  Affirmed    ...      Journal Abstract   \n",
       "\n",
       "                                      result_display  section  \\\n",
       "0  {'date': '2010-03-01T00:00:00Z', 'result_conte...  UNKNOWN   \n",
       "1  {'date': '2010-03-01T00:00:00Z', 'result_conte...  UNKNOWN   \n",
       "2  {'date': '2016-01-01T00:00:00Z', 'result_conte...  UNKNOWN   \n",
       "3  {'date': '2016-01-01T00:00:00Z', 'result_conte...  UNKNOWN   \n",
       "4  {'date': '2003-12-12T00:00:00Z', 'result_conte...  UNKNOWN   \n",
       "\n",
       "                                            sentence        solr_id  source  \\\n",
       "0  Approximately 4 hours after cesarean section, ...  pmid_20434111  PubMed   \n",
       "1  This case illustrates that we should bear in m...  pmid_20434111  PubMed   \n",
       "2  A 26-year-old white woman diagnosed with syste...  pmid_26757303  PubMed   \n",
       "3  Three months later, she presented to our clini...  pmid_26757303  PubMed   \n",
       "4  A 63-year-old woman was admitted with diffuse ...  pmid_14673740  PubMed   \n",
       "\n",
       "  start                                            subject temporality  \\\n",
       "0    58  Acta anaesthesiologica Taiwanica : official jo...      Recent   \n",
       "1    77  Acta anaesthesiologica Taiwanica : official jo...      Recent   \n",
       "2   129                                              Chest      Recent   \n",
       "3    74                                              Chest      Recent   \n",
       "4    77         Deutsche medizinische Wochenschrift (1946)      Recent   \n",
       "\n",
       "        term  \n",
       "0  orthopnea  \n",
       "1  orthopnea  \n",
       "2  orthopnea  \n",
       "3  orthopnea  \n",
       "4  orthopnea  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_csv_df = pd.read_csv(intermediate_csv)\n",
    "inter_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, you may notice that the `TermFinder` function peforms a picks up both negated and affirmed cases as well as historical, hypothetical, and any other mentions.  TermFinder can be tuned to pull only specific results. Such as in the example below, which only gets positive mentions.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea],\n",
    "    negated:\"Affirmed\"\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://localhost:5000/job_results/153/phenotype_intermediate\",\n",
      "    \"job_id\": \"153\",\n",
      "    \"luigi_task_monitoring\": \"http://localhost:8082/static/visualiser/index.html#search__search=job=153\",\n",
      "    \"main_results_csv\": \"http://localhost:5000/job_results/153/phenotype\",\n",
      "    \"phenotype_config\": \"http://localhost:5000/phenotype_id/153\",\n",
      "    \"phenotype_id\": \"153\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://localhost:5000/pipeline_id/178\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        178\n",
      "    ],\n",
      "    \"status_endpoint\": \"http://localhost:5000/status/153\"\n",
      "}\n",
      "Job in progress............\n",
      "Job successfully completed!\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.TermFinder({\n",
    "    termset:[Orthopnea],\n",
    "    negated:\"Affirmed\"\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because many term searchers are actually looking for non-negated, non-hypothetical, subject=patient mentions, we provide a convenient function `ProviderAssertion` to capture those mentions without needing to configure TermFinder. \n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "\n",
    "//phenotype name\n",
    "phenotype \"Orthopnea\" version \"2\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Find NYHA Class III/IV patients or those with EF<30%\n",
    "For the next component of this tutorial, we will aim to extract specific values about CHF from the chart.  This is commonly done with the [ValueExtraction](https://claritynlp.readthedocs.io/en/latest/developer_guide/algorithms/value_extraction.html) function.  Value extractions can be numeric as well as an enumerated list of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will be searching for ejection fraction values using a very simple algorithm.  Specifically, we will be looking for certain terms and subsequent values that would be typical for EF values.  (There are many more sophisticated methods to find ejection fraction (e.g [Kim et al](https://www.ncbi.nlm.nih.gov/pubmed/28163196)).)  We will then constrain the \"final\" cohort to only those with an EF < 30.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"Ejection Fraction Values\" version \"1\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "//logical Context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define final LowEFPatient:\n",
    "    where EjectionFraction.value <= 30;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://localhost:5000/job_results/154/phenotype_intermediate\",\n",
      "    \"job_id\": \"154\",\n",
      "    \"luigi_task_monitoring\": \"http://localhost:8082/static/visualiser/index.html#search__search=job=154\",\n",
      "    \"main_results_csv\": \"http://localhost:5000/job_results/154/phenotype\",\n",
      "    \"phenotype_config\": \"http://localhost:5000/phenotype_id/154\",\n",
      "    \"phenotype_id\": \"154\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://localhost:5000/pipeline_id/179\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        179\n",
      "    ],\n",
      "    \"status_endpoint\": \"http://localhost:5000/status/154\"\n",
      "}\n",
      "Job in progress...............\n",
      "Job successfully completed!\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"Ejection Fraction Values\" version \"1\";\n",
    "\n",
    "//include Clarity main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "//logical Context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define final LowEFPatient:\n",
    "    where EjectionFraction.value <= 30;\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `final` declaration refers to a cohort definition and typically involves some logic.  So in this case we defined an extraction process to pull all values between 10 and 85 following EF, LVEF, etc.  We then specified a `context`, meaning that the logic should operate on the level of a patient.  (The other option is Document context, which we will describe in a future session.)  Our logical rule stated that patients with an EjectionFraction <= 30 would make our criteria for a Low EF Patient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be found at the main_results_csv URL from your API response, or if  you ran here in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:5000/job_results/154/phenotype\n"
     ]
    }
   ],
   "source": [
    "print(main_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_ids_1</th>\n",
       "      <th>batch</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>concept_code_system</th>\n",
       "      <th>condition</th>\n",
       "      <th>context_type</th>\n",
       "      <th>display_name</th>\n",
       "      <th>end</th>\n",
       "      <th>inserted_date</th>\n",
       "      <th>...</th>\n",
       "      <th>solr_id</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>subject</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "      <th>values_before_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>622778771e352e9afcb5e683</td>\n",
       "      <td>6227786b48b11a9eeeb5e5f7</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RANGE</td>\n",
       "      <td>subject</td>\n",
       "      <td>EjectionFraction</td>\n",
       "      <td>108</td>\n",
       "      <td>2022-03-08 10:38:19.958000</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_30287144</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>89</td>\n",
       "      <td>Journal of Ayurveda and integrative medicine</td>\n",
       "      <td>ef</td>\n",
       "      <td>EF) 10-30%) wherein</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>622778771e352e9afcb5e684</td>\n",
       "      <td>6227786c48b11a9eeeb5e5ff</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>subject</td>\n",
       "      <td>EjectionFraction</td>\n",
       "      <td>184</td>\n",
       "      <td>2022-03-08 10:38:20.908000</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_29929385</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>176</td>\n",
       "      <td>Journal of cardiovascular pharmacology and the...</td>\n",
       "      <td>lvef</td>\n",
       "      <td>LVEF] 30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>622778771e352e9afcb5e685</td>\n",
       "      <td>6227786d48b11a9eeeb5e601</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>subject</td>\n",
       "      <td>EjectionFraction</td>\n",
       "      <td>186</td>\n",
       "      <td>2022-03-08 10:38:21.093000</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_30892806</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>179</td>\n",
       "      <td>European journal of heart failure</td>\n",
       "      <td>lvef</td>\n",
       "      <td>LVEF 30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>622778771e352e9afcb5e686</td>\n",
       "      <td>6227786d48b11a9eeeb5e605</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>subject</td>\n",
       "      <td>EjectionFraction</td>\n",
       "      <td>52</td>\n",
       "      <td>2022-03-08 10:38:21.474000</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_30835055</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>43</td>\n",
       "      <td>Internal and emergency medicine</td>\n",
       "      <td>lvef</td>\n",
       "      <td>LVEF by10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622778771e352e9afcb5e687</td>\n",
       "      <td>6227786d48b11a9eeeb5e60b</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>subject</td>\n",
       "      <td>EjectionFraction</td>\n",
       "      <td>114</td>\n",
       "      <td>2022-03-08 10:38:21.686000</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_30766004</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>82</td>\n",
       "      <td>Journal of the Saudi Heart Association</td>\n",
       "      <td>ejection fraction</td>\n",
       "      <td>ejection fraction (HFrEF) and 22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                    _ids_1  batch  concept_code  \\\n",
       "0  622778771e352e9afcb5e683  6227786b48b11a9eeeb5e5f7     90           NaN   \n",
       "1  622778771e352e9afcb5e684  6227786c48b11a9eeeb5e5ff     30           NaN   \n",
       "2  622778771e352e9afcb5e685  6227786d48b11a9eeeb5e601     30           NaN   \n",
       "3  622778771e352e9afcb5e686  6227786d48b11a9eeeb5e605     30           NaN   \n",
       "4  622778771e352e9afcb5e687  6227786d48b11a9eeeb5e60b      0           NaN   \n",
       "\n",
       "   concept_code_system condition context_type      display_name  end  \\\n",
       "0                  NaN     RANGE      subject  EjectionFraction  108   \n",
       "1                  NaN     EQUAL      subject  EjectionFraction  184   \n",
       "2                  NaN     EQUAL      subject  EjectionFraction  186   \n",
       "3                  NaN     EQUAL      subject  EjectionFraction   52   \n",
       "4                  NaN     EQUAL      subject  EjectionFraction  114   \n",
       "\n",
       "                inserted_date         ...                 solr_id  source  \\\n",
       "0  2022-03-08 10:38:19.958000         ...           pmid_30287144  PubMed   \n",
       "1  2022-03-08 10:38:20.908000         ...           pmid_29929385  PubMed   \n",
       "2  2022-03-08 10:38:21.093000         ...           pmid_30892806  PubMed   \n",
       "3  2022-03-08 10:38:21.474000         ...           pmid_30835055  PubMed   \n",
       "4  2022-03-08 10:38:21.686000         ...           pmid_30766004  PubMed   \n",
       "\n",
       "   start                                            subject  \\\n",
       "0     89       Journal of Ayurveda and integrative medicine   \n",
       "1    176  Journal of cardiovascular pharmacology and the...   \n",
       "2    179                  European journal of heart failure   \n",
       "3     43                    Internal and emergency medicine   \n",
       "4     82             Journal of the Saudi Heart Association   \n",
       "\n",
       "                term                              text  value  value1  value2  \\\n",
       "0                 ef               EF) 10-30%) wherein   10.0    10.0    30.0   \n",
       "1               lvef                          LVEF] 30   30.0    30.0     NaN   \n",
       "2               lvef                           LVEF 30   30.0    30.0     NaN   \n",
       "3               lvef                         LVEF by10   10.0    10.0     NaN   \n",
       "4  ejection fraction  ejection fraction (HFrEF) and 22   22.0    22.0     NaN   \n",
       "\n",
       "   values_before_terms  \n",
       "0                False  \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_csv_df = pd.read_csv(main_csv)\n",
    "final_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use ValueExtraction to pull out an enumerated value set (rather than a quantitative value).  See the example below for NYHA class.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "define NYHAClass:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://localhost:5000/job_results/155/phenotype_intermediate\",\n",
      "    \"job_id\": \"155\",\n",
      "    \"luigi_task_monitoring\": \"http://localhost:8082/static/visualiser/index.html#search__search=job=155\",\n",
      "    \"main_results_csv\": \"http://localhost:5000/job_results/155/phenotype\",\n",
      "    \"phenotype_config\": \"http://localhost:5000/phenotype_id/155\",\n",
      "    \"phenotype_id\": \"155\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://localhost:5000/pipeline_id/180\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        180\n",
      "    ],\n",
      "    \"status_endpoint\": \"http://localhost:5000/status/155\"\n",
      "}\n",
      "Job in progress...............\n",
      "Job successfully completed!\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "define NYHAClass:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>concept_code_system</th>\n",
       "      <th>condition</th>\n",
       "      <th>display_name</th>\n",
       "      <th>end</th>\n",
       "      <th>inserted_date</th>\n",
       "      <th>job_id</th>\n",
       "      <th>max_value</th>\n",
       "      <th>...</th>\n",
       "      <th>solr_id</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>subject</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "      <th>values_before_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6227787b48b11a9eeeb5e681</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>NYHAClass</td>\n",
       "      <td>145</td>\n",
       "      <td>2022-03-08 10:38:35.149000</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_28744959</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>137</td>\n",
       "      <td>Journal of cardiovascular electrophysiology</td>\n",
       "      <td>nyha</td>\n",
       "      <td>NYHA III</td>\n",
       "      <td>iii</td>\n",
       "      <td>iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6227787b48b11a9eeeb5e682</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>NYHAClass</td>\n",
       "      <td>113</td>\n",
       "      <td>2022-03-08 10:38:35.271000</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_29801082</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>96</td>\n",
       "      <td>JAMA cardiology</td>\n",
       "      <td>nyha</td>\n",
       "      <td>NYHA II to 49% (3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6227787b48b11a9eeeb5e683</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>NYHAClass</td>\n",
       "      <td>45</td>\n",
       "      <td>2022-03-08 10:38:35.352000</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_28430960</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>25</td>\n",
       "      <td>Europace : European pacing, arrhythmias, and c...</td>\n",
       "      <td>nyha</td>\n",
       "      <td>NYHA class III and 3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6227787b48b11a9eeeb5e684</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>NYHAClass</td>\n",
       "      <td>143</td>\n",
       "      <td>2022-03-08 10:38:35.436000</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_29267340</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>97</td>\n",
       "      <td>PloS one</td>\n",
       "      <td>nyha</td>\n",
       "      <td>NYHA classification during follow-up were univ</td>\n",
       "      <td>iv</td>\n",
       "      <td>iv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6227787b48b11a9eeeb5e685</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUAL</td>\n",
       "      <td>NYHAClass</td>\n",
       "      <td>63</td>\n",
       "      <td>2022-03-08 10:38:35.592000</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pmid_29520133</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>49</td>\n",
       "      <td>Clinical interventions in aging</td>\n",
       "      <td>nyha</td>\n",
       "      <td>NYHA III or IV</td>\n",
       "      <td>iv</td>\n",
       "      <td>iv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  batch  concept_code  concept_code_system  \\\n",
       "0  6227787b48b11a9eeeb5e681     20           NaN                  NaN   \n",
       "1  6227787b48b11a9eeeb5e682     20           NaN                  NaN   \n",
       "2  6227787b48b11a9eeeb5e683     20           NaN                  NaN   \n",
       "3  6227787b48b11a9eeeb5e684     20           NaN                  NaN   \n",
       "4  6227787b48b11a9eeeb5e685     20           NaN                  NaN   \n",
       "\n",
       "  condition display_name  end               inserted_date  job_id  max_value  \\\n",
       "0     EQUAL    NYHAClass  145  2022-03-08 10:38:35.149000     155        NaN   \n",
       "1     EQUAL    NYHAClass  113  2022-03-08 10:38:35.271000     155        NaN   \n",
       "2     EQUAL    NYHAClass   45  2022-03-08 10:38:35.352000     155        NaN   \n",
       "3     EQUAL    NYHAClass  143  2022-03-08 10:38:35.436000     155        NaN   \n",
       "4     EQUAL    NYHAClass   63  2022-03-08 10:38:35.592000     155        NaN   \n",
       "\n",
       "          ...                solr_id  source start  \\\n",
       "0         ...          pmid_28744959  PubMed   137   \n",
       "1         ...          pmid_29801082  PubMed    96   \n",
       "2         ...          pmid_28430960  PubMed    25   \n",
       "3         ...          pmid_29267340  PubMed    97   \n",
       "4         ...          pmid_29520133  PubMed    49   \n",
       "\n",
       "                                             subject  term  \\\n",
       "0        Journal of cardiovascular electrophysiology  nyha   \n",
       "1                                    JAMA cardiology  nyha   \n",
       "2  Europace : European pacing, arrhythmias, and c...  nyha   \n",
       "3                                           PloS one  nyha   \n",
       "4                    Clinical interventions in aging  nyha   \n",
       "\n",
       "                                             text value value1 value2  \\\n",
       "0                                        NYHA III   iii    iii    NaN   \n",
       "1                               NYHA II to 49% (3     3      3    NaN   \n",
       "2                            NYHA class III and 3     3      3    NaN   \n",
       "3  NYHA classification during follow-up were univ    iv     iv    NaN   \n",
       "4                                  NYHA III or IV    iv     iv    NaN   \n",
       "\n",
       "  values_before_terms  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view intermediate results\n",
    "inter_csv_df = pd.read_csv(intermediate_csv)\n",
    "inter_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Bringing the criteria together to find the target CHF cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final step in example 1, we want to bring together the above criteria to generate our final cohort.\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "//termsets\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "//data extractions\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "\n",
    "define NYHAClass34:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "\n",
    "//logical context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define LowEF:\n",
    "    where EjectionFraction.value <= 30;\n",
    "\n",
    "define SevereCHF:\n",
    "    where NYHAClass34 OR LowEF;\n",
    "    \n",
    "define final SevereCHFwithOrthopnea:\n",
    "    where SevereCHF AND hasOrthopnea;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://localhost:5000/job_results/156/phenotype_intermediate\",\n",
      "    \"job_id\": \"156\",\n",
      "    \"luigi_task_monitoring\": \"http://localhost:8082/static/visualiser/index.html#search__search=job=156\",\n",
      "    \"main_results_csv\": \"http://localhost:5000/job_results/156/phenotype\",\n",
      "    \"phenotype_config\": \"http://localhost:5000/phenotype_id/156\",\n",
      "    \"phenotype_id\": \"156\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://localhost:5000/pipeline_id/181\",\n",
      "        \"http://localhost:5000/pipeline_id/182\",\n",
      "        \"http://localhost:5000/pipeline_id/183\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        181,\n",
      "        182,\n",
      "        183\n",
      "    ],\n",
      "    \"status_endpoint\": \"http://localhost:5000/status/156\"\n",
      "}\n",
      "Job in progress......................................\n",
      "Job successfully completed!\n"
     ]
    }
   ],
   "source": [
    "# Sample NLPQL\n",
    "nlpql ='''\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"Final CHF Cohort\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "//termsets\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "//data extractions\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "\n",
    "define NYHAClass34:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "\n",
    "//logical context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define LowEF:\n",
    "    where EjectionFraction.value <= 30;\n",
    "\n",
    "define SevereCHF:\n",
    "    where NYHAClass34 OR LowEF;\n",
    "    \n",
    "define final SevereCHFwithOrthopnea:\n",
    "    where SevereCHF AND hasOrthopnea;\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_ids_1</th>\n",
       "      <th>_ids_2</th>\n",
       "      <th>_ids_3</th>\n",
       "      <th>batch_1</th>\n",
       "      <th>batch_2</th>\n",
       "      <th>concept_code_1</th>\n",
       "      <th>concept_code_2</th>\n",
       "      <th>concept_code_system_1</th>\n",
       "      <th>concept_code_system_2</th>\n",
       "      <th>...</th>\n",
       "      <th>start_2</th>\n",
       "      <th>subject</th>\n",
       "      <th>temporality</th>\n",
       "      <th>term_1</th>\n",
       "      <th>term_2</th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "      <th>values_before_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>622778ae98af687cdfb5e96b</td>\n",
       "      <td>622778a348b11a9eeeb5e840</td>\n",
       "      <td>622778ae98af687cdfb5e8ec</td>\n",
       "      <td>6227789248b11a9eeeb5e78b</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>International journal of cardiology</td>\n",
       "      <td>Recent</td>\n",
       "      <td>nyha</td>\n",
       "      <td>orthopnea</td>\n",
       "      <td>NYHA class (NYHA III</td>\n",
       "      <td>iii</td>\n",
       "      <td>iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>622778ae98af687cdfb5e96c</td>\n",
       "      <td>622778a848b11a9eeeb5e880</td>\n",
       "      <td>622778ae98af687cdfb5e8ed</td>\n",
       "      <td>6227789248b11a9eeeb5e78b</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>International journal of cardiology</td>\n",
       "      <td>Recent</td>\n",
       "      <td>nyha</td>\n",
       "      <td>orthopnea</td>\n",
       "      <td>NYHA I and II (23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>622778ae98af687cdfb5e96d</td>\n",
       "      <td>622778a848b11a9eeeb5e881</td>\n",
       "      <td>622778ae98af687cdfb5e8ee</td>\n",
       "      <td>6227789248b11a9eeeb5e78b</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>International journal of cardiology</td>\n",
       "      <td>Recent</td>\n",
       "      <td>nyha</td>\n",
       "      <td>orthopnea</td>\n",
       "      <td>NYHA III and IV</td>\n",
       "      <td>iv</td>\n",
       "      <td>iv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>622778ae98af687cdfb5e96e</td>\n",
       "      <td>622778aa48b11a9eeeb5e89b</td>\n",
       "      <td>622778ae98af687cdfb5e8ef</td>\n",
       "      <td>6227789248b11a9eeeb5e78b</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>International journal of cardiology</td>\n",
       "      <td>Recent</td>\n",
       "      <td>nyha</td>\n",
       "      <td>orthopnea</td>\n",
       "      <td>NYHA classes III-IV</td>\n",
       "      <td>iv</td>\n",
       "      <td>iv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622778ae98af687cdfb5e96f</td>\n",
       "      <td>622778aa48b11a9eeeb5e89c</td>\n",
       "      <td>622778ae98af687cdfb5e8f0</td>\n",
       "      <td>6227789248b11a9eeeb5e78b</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>International journal of cardiology</td>\n",
       "      <td>Recent</td>\n",
       "      <td>nyha</td>\n",
       "      <td>orthopnea</td>\n",
       "      <td>NYHA class I-III</td>\n",
       "      <td>iii</td>\n",
       "      <td>iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                    _ids_1  \\\n",
       "0  622778ae98af687cdfb5e96b  622778a348b11a9eeeb5e840   \n",
       "1  622778ae98af687cdfb5e96c  622778a848b11a9eeeb5e880   \n",
       "2  622778ae98af687cdfb5e96d  622778a848b11a9eeeb5e881   \n",
       "3  622778ae98af687cdfb5e96e  622778aa48b11a9eeeb5e89b   \n",
       "4  622778ae98af687cdfb5e96f  622778aa48b11a9eeeb5e89c   \n",
       "\n",
       "                     _ids_2                    _ids_3  batch_1  batch_2  \\\n",
       "0  622778ae98af687cdfb5e8ec  6227789248b11a9eeeb5e78b       60       60   \n",
       "1  622778ae98af687cdfb5e8ed  6227789248b11a9eeeb5e78b        0       60   \n",
       "2  622778ae98af687cdfb5e8ee  6227789248b11a9eeeb5e78b        0       60   \n",
       "3  622778ae98af687cdfb5e8ef  6227789248b11a9eeeb5e78b       40       60   \n",
       "4  622778ae98af687cdfb5e8f0  6227789248b11a9eeeb5e78b       40       60   \n",
       "\n",
       "   concept_code_1  concept_code_2  concept_code_system_1  \\\n",
       "0             NaN             NaN                    NaN   \n",
       "1             NaN             NaN                    NaN   \n",
       "2             NaN             NaN                    NaN   \n",
       "3             NaN             NaN                    NaN   \n",
       "4             NaN             NaN                    NaN   \n",
       "\n",
       "   concept_code_system_2         ...         start_2  \\\n",
       "0                    NaN         ...              34   \n",
       "1                    NaN         ...              34   \n",
       "2                    NaN         ...              34   \n",
       "3                    NaN         ...              34   \n",
       "4                    NaN         ...              34   \n",
       "\n",
       "                               subject temporality term_1     term_2  \\\n",
       "0  International journal of cardiology      Recent   nyha  orthopnea   \n",
       "1  International journal of cardiology      Recent   nyha  orthopnea   \n",
       "2  International journal of cardiology      Recent   nyha  orthopnea   \n",
       "3  International journal of cardiology      Recent   nyha  orthopnea   \n",
       "4  International journal of cardiology      Recent   nyha  orthopnea   \n",
       "\n",
       "                   text value value1 value2 values_before_terms  \n",
       "0  NYHA class (NYHA III   iii    iii    NaN               False  \n",
       "1     NYHA I and II (23     3      3    NaN               False  \n",
       "2       NYHA III and IV    iv     iv    NaN               False  \n",
       "3   NYHA classes III-IV    iv     iv    NaN               False  \n",
       "4      NYHA class I-III   iii    iii    NaN               False  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_csv_df = pd.read_csv(main_csv)\n",
    "final_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above case, we may need to increase our limit beyond 100 documents to find many matching patients, because multiple criteria are required and a small sample may not be enough.  Try increasing to 500 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Results through the ClarityNLP UI\n",
    "Downloading the raw CSV results is handy for analysis and data manipulation.  However, a domain-oriented end user may be more interested in just exploring and validating the final results without getting into all the programmatic details.  That's where the Results Viewer comes in, which in a typical installation will be found at localhost:8200/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screen%20Shot%202018-08-29%20at%209.33.35%20AM.png](assets/Clarity Validator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #2: Capturing Information on Patient Race\n",
    "Although there are many useful [core algorithms](https://claritynlp.readthedocs.io/en/latest/developer_guide/index.html#task-algorithms) in ClarityNLP, users will frequently want to extend its functionality.  In this second example, we will explore how to extend ClarityNLP when the built in algorithms are inadequate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we'd like to identify the patient's race.  While some version of this could probably we done with simple search terms, a custom algorithm will likely be necessary.  Below is an example of a custom Python algorithm written to extract race information from a document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "str_sep = r'(\\s-\\s|-\\s|\\s-|\\s)'\n",
    "str_word = r'\\b[-a-z.\\d]+'\n",
    "str_punct = r'[,.\\s]*'\n",
    "str_words = r'(' + str_word + str_punct + r'){0,6}'\n",
    "str_person = r'\\b(gentleman|gentlewoman|male|female|man|woman|person|'    +\\\n",
    "             r'child|boy|girl|infant|baby|newborn|neonate|individual)\\b'\n",
    "str_category = r'\\b(american' + str_sep + r'indian|'                      +\\\n",
    "               r'alaska' + str_sep + r'native|asian|'                     +\\\n",
    "               r'african' + str_sep + r'american|black|negro|'            +\\\n",
    "               r'native' + str_sep + r'hawaiian|'                         +\\\n",
    "               r'other' + str_sep + r'pacific' + str_sep + r'islander|'   +\\\n",
    "               r'pacific' + str_sep + r'islander|'                        +\\\n",
    "               r'native' + str_sep + r'american|'                         +\\\n",
    "               r'white|caucasian|european)'\n",
    "\n",
    "str_race1 = r'(\\brace:?\\s*)' + r'(?P<category>' + str_category + r')'\n",
    "regex_race1 = re.compile(str_race1, re.IGNORECASE)\n",
    "str_race2 = r'(?P<category>' + str_category + r')' + str_punct    +\\\n",
    "            str_words + str_person\n",
    "regex_race2 = re.compile(str_race2, re.IGNORECASE)\n",
    "str_race3 = str_person + str_punct + str_words + r'(?P<category>' +\\\n",
    "            str_category + r')'\n",
    "regex_race3 = re.compile(str_race3, re.IGNORECASE)\n",
    "REGEXES = [regex_race1, regex_race2, regex_race3]\n",
    "\n",
    "RACE_FINDER_RESULT_FIELDS = ['sentence_index', 'start', 'end', 'race',\n",
    "                             'normalized_race']\n",
    "RaceFinderResult = namedtuple('RaceFinderResult', RACE_FINDER_RESULT_FIELDS)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "def normalize(race_text):\n",
    "    \"\"\"\n",
    "    Convert a matching race string to a 'normalized' version.\n",
    "    \"\"\"\n",
    "\n",
    "    NORM_MAP = {\n",
    "        'african american':'black',\n",
    "        'negro':'black',\n",
    "        'caucasian':'white',\n",
    "        'european':'white',\n",
    "    }\n",
    "    \n",
    "    # convert to lowercase, remove dashes, collapse repeated whitespace\n",
    "    race = race_text.lower()\n",
    "    race = re.sub(r'[-]+', '', race)\n",
    "    race = re.sub(r'\\s+', ' ', race)\n",
    "\n",
    "    if race in NORM_MAP:\n",
    "        return NORM_MAP[race]\n",
    "    else:\n",
    "        return race\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "def find_race(sentence_list):\n",
    "    \"\"\"\n",
    "    Scan a list of sentences and run race-finding regexes on each.\n",
    "    Return a dict that maps sentence_index -> race_category.\n",
    "    \"\"\"\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    found_match = False\n",
    "    for i in range(len(sentence_list)):\n",
    "        s = sentence_list[i]\n",
    "        for regex in REGEXES:\n",
    "            match = regex.search(s)\n",
    "            if match:\n",
    "                match_text = match.group('category')\n",
    "                start = match.start()\n",
    "                end   = match.end()\n",
    "                normalized = normalize(match_text)\n",
    "                result = RaceFinderResult(i, start, end, match_text, normalized)\n",
    "                result_list.append(result)\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        # Reports are unlikely to have more than one sentence stating the\n",
    "        # patient's race.\n",
    "        if found_match:\n",
    "            break\n",
    "            \n",
    "    return result_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without going into the details, this algorithm parses text to find race information, normalizes it to standard terms, and passes back the result.  In order to run this algorithm using NLPQL in ClarityNLP, we create what is called a custom task.  Below is code that creates the CustomTask wrapping this function and provides it with the documents and handling of result ouput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# use this name in NLPQL\n",
    "    task_name = \"RaceFinderTask\"\n",
    "\n",
    "    def run_custom_task(self, temp_file, mongo_client: MongoClient):\n",
    "\n",
    "        # for each document in the NLPQL-specified doc set\n",
    "        for doc in self.docs:\n",
    "\n",
    "            # all sentences in this document\n",
    "            sentence_list = self.get_document_sentences(doc)\n",
    "\n",
    "            # all race results in this document\n",
    "            result_list = find_race(sentence_list)\n",
    "                \n",
    "            if len(result_list) > 0:\n",
    "                for result in result_list:\n",
    "                    obj = {\n",
    "                        'sentence':sentence_list[result.sentence_index],\n",
    "                        'start':result.start,\n",
    "                        'end':result.end,\n",
    "                        'value':result.race,\n",
    "                        'value_normalized':result.normalized_race,\n",
    "                    }\n",
    "            \n",
    "                    self.write_result_data(temp_file, mongo_client, doc, obj)\n",
    "                    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files can be split into two or can be combined as shown in the final custom task below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-08 10:39:31-EST] ERROR in claritynlp_logging: \"No option 'username' in section: 'mongo'\"\n",
      "[2022-03-08 10:39:31-EST] ERROR in claritynlp_logging: \"No option 'password' in section: 'mongo'\"\n",
      "[2022-03-08 10:39:32-EST] ERROR in claritynlp_logging: \"No section: 'results_client'\"\n",
      "[2022-03-08 10:39:32-EST] ERROR in claritynlp_logging: \"No option 'batch_size' in section: 'solr'\"\n",
      "[2022-03-08 10:39:32-EST] ERROR in claritynlp_logging: \"No section: 'report_mapper'\"\n",
      "[2022-03-08 10:39:32-EST] ERROR in claritynlp_logging: \"No section: 'report_mapper'\"\n",
      "[2022-03-08 10:39:33-EST] ERROR in claritynlp_logging: \"No section: 'report_mapper'\"\n",
      "[2022-03-08 10:39:33-EST] ERROR in claritynlp_logging: \"No section: 'apis'\"\n",
      "[2022-03-08 10:39:33-EST] ERROR in claritynlp_logging: \"No section: 'redis'\"\n",
      "[2022-03-08 10:39:33-EST] ERROR in claritynlp_logging: \"No section: 'redis'\"\n",
      "[2022-03-08 10:39:34-EST] ERROR in claritynlp_logging: \"No section: 'redis'\"\n",
      "[2022-03-08 10:39:34-EST] ERROR in claritynlp_logging: \"No section: 'optimizations'\"\n",
      "[2022-03-08 10:39:34-EST] ERROR in claritynlp_logging: \"No section: 'optimizations'\"\n",
      "[2022-03-08 10:39:34-EST] ERROR in claritynlp_logging: \"No section: 'optimizations'\"\n",
      "[2022-03-08 10:39:35-EST] ERROR in claritynlp_logging: \"No section: 'optimizations'\"\n",
      "[2022-03-08 10:39:35-EST] ERROR in claritynlp_logging: \"No option 'cql_eval_url' in section: 'local'\"\n",
      "[2022-03-08 10:39:35-EST] ERROR in claritynlp_logging: \"No option 'fhir_data_service_uri' in section: 'local'\"\n",
      "[2022-03-08 10:39:35-EST] ERROR in claritynlp_logging: \"No option 'fhir_auth_type' in section: 'local'\"\n",
      "[2022-03-08 10:39:36-EST] ERROR in claritynlp_logging: \"No option 'fhir_auth_token' in section: 'local'\"\n",
      "[2022-03-08 10:39:36-EST] ERROR in claritynlp_logging: \"No option 'fhir_terminology_service_uri' in section: 'local'\"\n",
      "[2022-03-08 10:39:36-EST] ERROR in claritynlp_logging: \"No option 'fhir_terminology_service_endpoint' in section: 'local'\"\n",
      "[2022-03-08 10:39:36-EST] ERROR in claritynlp_logging: \"No option 'fhir_terminology_user' in section: 'local'\"\n",
      "[2022-03-08 10:39:37-EST] ERROR in claritynlp_logging: \"No option 'fhir_terminology_password' in section: 'local'\"\n",
      "WARNING: 1 shift/reduce conflict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-08 10:39:37-EST] INFO in claritynlp_logging: 'Initializing models for term finder...'\n",
      "[2022-03-08 10:39:37-EST] INFO in claritynlp_logging: 'section_tagger_init...'\n",
      "[2022-03-08 10:39:38-EST] INFO in claritynlp_logging: ('Context') 'Context init...'\n",
      "[2022-03-08 10:39:38-EST] INFO in claritynlp_logging: 'Context init...'\n",
      "[2022-03-08 10:39:38-EST] INFO in claritynlp_logging: 'Segmentation init...'\n",
      "[2022-03-08 10:39:39-EST] INFO in claritynlp_logging: 'Done initializing models for term finder...'\n",
      "[2022-03-08 10:39:39-EST] INFO in claritynlp_logging: 'Initializing models for value extractor...'\n",
      "[2022-03-08 10:39:39-EST] INFO in claritynlp_logging: 'Done initializing models for value extractor...'\n",
      "[2022-03-08 10:39:40-EST] INFO in claritynlp_logging: 'Initializing models for measurement finder...'\n",
      "[2022-03-08 10:39:40-EST] INFO in claritynlp_logging: 'Done initializing models for measurement finder..'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pymongo import MongoClient\n",
    "from collections import namedtuple\n",
    "from tasks.task_utilities import BaseTask\n",
    "\n",
    "str_sep = r'(\\s-\\s|-\\s|\\s-|\\s)'\n",
    "str_word = r'\\b[-a-z.\\d]+'\n",
    "str_punct = r'[,.\\s]*'\n",
    "str_words = r'(' + str_word + str_punct + r'){0,6}'\n",
    "str_person = r'\\b(gentleman|gentlewoman|male|female|man|woman|person|'    +\\\n",
    "             r'child|boy|girl|infant|baby|newborn|neonate|individual)\\b'\n",
    "str_category = r'\\b(american' + str_sep + r'indian|'                      +\\\n",
    "               r'alaska' + str_sep + r'native|asian|'                     +\\\n",
    "               r'african' + str_sep + r'american|black|negro|'            +\\\n",
    "               r'native' + str_sep + r'hawaiian|'                         +\\\n",
    "               r'other' + str_sep + r'pacific' + str_sep + r'islander|'   +\\\n",
    "               r'pacific' + str_sep + r'islander|'                        +\\\n",
    "               r'native' + str_sep + r'american|'                         +\\\n",
    "               r'white|caucasian|european)'\n",
    "\n",
    "str_race1 = r'(\\brace:?\\s*)' + r'(?P<category>' + str_category + r')'\n",
    "regex_race1 = re.compile(str_race1, re.IGNORECASE)\n",
    "str_race2 = r'(?P<category>' + str_category + r')' + str_punct    +\\\n",
    "            str_words + str_person\n",
    "regex_race2 = re.compile(str_race2, re.IGNORECASE)\n",
    "str_race3 = str_person + str_punct + str_words + r'(?P<category>' +\\\n",
    "            str_category + r')'\n",
    "regex_race3 = re.compile(str_race3, re.IGNORECASE)\n",
    "REGEXES = [regex_race1, regex_race2, regex_race3]\n",
    "\n",
    "RACE_FINDER_RESULT_FIELDS = ['sentence_index', 'start', 'end', 'race',\n",
    "                             'normalized_race']\n",
    "RaceFinderResult = namedtuple('RaceFinderResult', RACE_FINDER_RESULT_FIELDS)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "def normalize(race_text):\n",
    "    \"\"\"\n",
    "    Convert a matching race string to a 'normalized' version.\n",
    "    \"\"\"\n",
    "\n",
    "    NORM_MAP = {\n",
    "        'african american':'black',\n",
    "        'negro':'black',\n",
    "        'caucasian':'white',\n",
    "        'european':'white',\n",
    "    }\n",
    "    \n",
    "    # convert to lowercase, remove dashes, collapse repeated whitespace\n",
    "    race = race_text.lower()\n",
    "    race = re.sub(r'[-]+', '', race)\n",
    "    race = re.sub(r'\\s+', ' ', race)\n",
    "\n",
    "    if race in NORM_MAP:\n",
    "        return NORM_MAP[race]\n",
    "    else:\n",
    "        return race\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "def find_race(sentence_list):\n",
    "    \"\"\"\n",
    "    Scan a list of sentences and run race-finding regexes on each.\n",
    "    Return a dict that maps sentence_index -> race_category.\n",
    "    \"\"\"\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    found_match = False\n",
    "    for i in range(len(sentence_list)):\n",
    "        s = sentence_list[i]\n",
    "        for regex in REGEXES:\n",
    "            match = regex.search(s)\n",
    "            if match:\n",
    "                match_text = match.group('category')\n",
    "                start = match.start()\n",
    "                end   = match.end()\n",
    "                normalized = normalize(match_text)\n",
    "                result = RaceFinderResult(i, start, end, match_text, normalized)\n",
    "                result_list.append(result)\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        # Reports are unlikely to have more than one sentence stating the\n",
    "        # patient's race.\n",
    "        if found_match:\n",
    "            break\n",
    "            \n",
    "    return result_list\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "class RaceFinderTask(BaseTask):\n",
    "    \"\"\"\n",
    "    A custom task for finding a patient's race.\n",
    "    \"\"\"\n",
    "    \n",
    "    # use this name in NLPQL\n",
    "    task_name = \"RaceFinderTask\"\n",
    "\n",
    "    def run_custom_task(self, temp_file, mongo_client: MongoClient):\n",
    "\n",
    "        # for each document in the NLPQL-specified doc set\n",
    "        for doc in self.docs:\n",
    "\n",
    "            # all sentences in this document\n",
    "            sentence_list = self.get_document_sentences(doc)\n",
    "\n",
    "            # all race results in this document\n",
    "            result_list = find_race(sentence_list)\n",
    "                \n",
    "            if len(result_list) > 0:\n",
    "                for result in result_list:\n",
    "                    obj = {\n",
    "                        'sentence':sentence_list[result.sentence_index],\n",
    "                        'start':result.start,\n",
    "                        'end':result.end,\n",
    "                        'value':result.race,\n",
    "                        'value_normalized':result.normalized_race,\n",
    "                    }\n",
    "            \n",
    "                    self.write_result_data(temp_file, mongo_client, doc, obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This race task can be called in NLPQL as follows:\n",
    "\n",
    "```java\n",
    "    limit 100;\n",
    "\n",
    "    phenotype \"Race Finder\" version \"1\";\n",
    "    include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "    documentset DischargeSummaries:\n",
    "        Clarity.createReportTagList([\"Discharge Summary\"]);\n",
    "\n",
    "    define RaceFinderFunction:\n",
    "        Clarity.RaceFinderTask({\n",
    "            documentset: [DischargeSummaries]\n",
    "        });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  This example is our first time using `documentset`, which allows us to specify a targeted list of documents such as Discharge Summaries or Radiology notes etc.  We will cover this is greater detail in future Cooking sessions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Successfully Submitted\n",
      "{\n",
      "    \"intermediate_results_csv\": \"http://18.220.133.76:5000/job_results/322/phenotype_intermediate\",\n",
      "    \"job_id\": \"322\",\n",
      "    \"luigi_task_monitoring\": \"http://18.220.133.76:8082/static/visualiser/index.html#search__search=job=322\",\n",
      "    \"main_results_csv\": \"http://18.220.133.76:5000/job_results/322/phenotype\",\n",
      "    \"phenotype_config\": \"http://18.220.133.76:5000/phenotype_id/322\",\n",
      "    \"phenotype_id\": \"322\",\n",
      "    \"pipeline_configs\": [\n",
      "        \"http://18.220.133.76:5000/pipeline_id/502\"\n",
      "    ],\n",
      "    \"pipeline_ids\": [\n",
      "        502\n",
      "    ],\n",
      "    \"results_viewer\": \"?job=322\",\n",
      "    \"status_endpoint\": \"http://18.220.133.76:5000/status/322\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "nlpql ='''\n",
    "limit 100;\n",
    "\n",
    "phenotype \"Race Finder\" version \"1\";\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "documentset DischargeSummaries:\n",
    "    Clarity.createReportTagList([\"Discharge Summary\"]);\n",
    "\n",
    "define RaceFinderFunction:\n",
    "    Clarity.RaceFinderTask({\n",
    "        documentset: [DischargeSummaries]\n",
    "    });\n",
    "'''\n",
    "run_result, main_csv, intermediate_csv, luigi = claritynlp.run_nlpql(nlpql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>end</th>\n",
       "      <th>inserted_date</th>\n",
       "      <th>job_id</th>\n",
       "      <th>nlpql_feature</th>\n",
       "      <th>owner</th>\n",
       "      <th>phenotype_final</th>\n",
       "      <th>pipeline_id</th>\n",
       "      <th>...</th>\n",
       "      <th>report_date</th>\n",
       "      <th>report_id</th>\n",
       "      <th>report_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>solr_id</th>\n",
       "      <th>source</th>\n",
       "      <th>start</th>\n",
       "      <th>subject</th>\n",
       "      <th>value</th>\n",
       "      <th>value_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b86a5fc2d76670a1377c786</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-08-29 13:56:12.628000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2106-07-16T00:00:00Z</td>\n",
       "      <td>10851</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Overweight white female.</td>\n",
       "      <td>10851</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>11</td>\n",
       "      <td>11350</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b86a6002d76670a1977c786</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>2018-08-29 13:56:16.440000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2106-05-03T00:00:00Z</td>\n",
       "      <td>8534</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Patient is a 46-year-old white female with his...</td>\n",
       "      <td>8534</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>25</td>\n",
       "      <td>15160</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b86a60a2d76670a1677c786</td>\n",
       "      <td>50</td>\n",
       "      <td>-1</td>\n",
       "      <td>54</td>\n",
       "      <td>2018-08-29 13:56:26.021000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2152-03-14T00:00:00Z</td>\n",
       "      <td>10838</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>In general, the patient was a middle-aged whit...</td>\n",
       "      <td>10838</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>42</td>\n",
       "      <td>26693</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5b86a60c2d76670a1377c787</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-08-29 13:56:28.023000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2187-05-10T00:00:00Z</td>\n",
       "      <td>10862</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Elderly caucasian gentleman with Parkinsonian ...</td>\n",
       "      <td>10862</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>8</td>\n",
       "      <td>1819</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b86a60d2d76670a1377c788</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>362</td>\n",
       "      <td>2018-08-29 13:56:29.182000</td>\n",
       "      <td>322</td>\n",
       "      <td>RaceFinderFunction</td>\n",
       "      <td>clarity</td>\n",
       "      <td>False</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>2100-10-19T00:00:00Z</td>\n",
       "      <td>10863</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Past Medical History: Hyperchol HTN Afib with ...</td>\n",
       "      <td>10863</td>\n",
       "      <td>MIMIC</td>\n",
       "      <td>347</td>\n",
       "      <td>25436</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  batch  concept_code  end  \\\n",
       "0  5b86a5fc2d76670a1377c786     75            -1   23   \n",
       "1  5b86a6002d76670a1977c786     25            -1   37   \n",
       "2  5b86a60a2d76670a1677c786     50            -1   54   \n",
       "3  5b86a60c2d76670a1377c787     75            -1   27   \n",
       "4  5b86a60d2d76670a1377c788     75            -1  362   \n",
       "\n",
       "                inserted_date  job_id       nlpql_feature    owner  \\\n",
       "0  2018-08-29 13:56:12.628000     322  RaceFinderFunction  clarity   \n",
       "1  2018-08-29 13:56:16.440000     322  RaceFinderFunction  clarity   \n",
       "2  2018-08-29 13:56:26.021000     322  RaceFinderFunction  clarity   \n",
       "3  2018-08-29 13:56:28.023000     322  RaceFinderFunction  clarity   \n",
       "4  2018-08-29 13:56:29.182000     322  RaceFinderFunction  clarity   \n",
       "\n",
       "   phenotype_final  pipeline_id       ...                  report_date  \\\n",
       "0            False          502       ...         2106-07-16T00:00:00Z   \n",
       "1            False          502       ...         2106-05-03T00:00:00Z   \n",
       "2            False          502       ...         2152-03-14T00:00:00Z   \n",
       "3            False          502       ...         2187-05-10T00:00:00Z   \n",
       "4            False          502       ...         2100-10-19T00:00:00Z   \n",
       "\n",
       "  report_id        report_type  \\\n",
       "0     10851  Discharge summary   \n",
       "1      8534  Discharge summary   \n",
       "2     10838  Discharge summary   \n",
       "3     10862  Discharge summary   \n",
       "4     10863  Discharge summary   \n",
       "\n",
       "                                            sentence solr_id  source start  \\\n",
       "0                           Overweight white female.   10851   MIMIC    11   \n",
       "1  Patient is a 46-year-old white female with his...    8534   MIMIC    25   \n",
       "2  In general, the patient was a middle-aged whit...   10838   MIMIC    42   \n",
       "3  Elderly caucasian gentleman with Parkinsonian ...   10862   MIMIC     8   \n",
       "4  Past Medical History: Hyperchol HTN Afib with ...   10863   MIMIC   347   \n",
       "\n",
       "   subject      value value_normalized  \n",
       "0    11350      white            white  \n",
       "1    15160      white            white  \n",
       "2    26693      white            white  \n",
       "3     1819  caucasian            white  \n",
       "4    25436  caucasian            white  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view intermediate results\n",
    "inter_csv_df = pd.read_csv(intermediate_csv)\n",
    "inter_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Combining race with other criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably gathered, you can now write NLPQL that will look for all patients matching our CHF criteria with the race information extracted above.  The NLPQL would look like this:\n",
    "\n",
    "```java\n",
    "limit 100;\n",
    "//phenotype name\n",
    "phenotype \"NYHA Class\" version \"1\";\n",
    "\n",
    "//include Clarity  main NLP libraries\n",
    "include ClarityCore version \"1.0\" called Clarity;\n",
    "\n",
    "//termsets\n",
    "termset Orthopnea:\n",
    "  [\"orthopnea\",\"orthopnoea\"];\n",
    "\n",
    "termset EjectionFractionTerms:\n",
    "  [\"ef\",\"ejection fraction\",\"lvef\"];\n",
    "\n",
    "termset NYHATerms:\n",
    "  [\"nyha\"];\n",
    "\n",
    "\n",
    "//documentsets\n",
    "documentset DischargeSummaries:\n",
    "    Clarity.createReportTagList([\"Discharge Summary\"]);\n",
    "\n",
    "\n",
    "//data extractions\n",
    "define hasOrthopnea:\n",
    "  Clarity.ProviderAssertion({\n",
    "    termset:[Orthopnea]\n",
    "    });\n",
    "\n",
    "define EjectionFraction:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[EjectionFractionTerms],\n",
    "    minimum_value: \"10\",\n",
    "    maximum_value: \"85\"\n",
    "    });\n",
    "\n",
    "\n",
    "define NYHAClass34:\n",
    "  Clarity.ValueExtraction({\n",
    "    termset:[NYHATerms],\n",
    "    enum_list: [\"3\",\"4\",\"iii\",\"iv\"];\n",
    "    });\n",
    "\n",
    "\n",
    "define Race:\n",
    "    Clarity.RaceFinderTask({\n",
    "        documentset: [DischargeSummaries]\n",
    "    });\n",
    "       \n",
    "\n",
    "//logical context (Patient, Document)\n",
    "context Patient;\n",
    "\n",
    "define LowEF:\n",
    "    where EjectionFraction.value <= 30;\n",
    "\n",
    "define SevereCHF:\n",
    "    where NYHAClass34 OR LowEF;\n",
    "\n",
    "define BlackRace:\n",
    "    where Race.normalized_value = 'black';\n",
    "    \n",
    "define final SevereCHFwithOrthopnea:\n",
    "    where SevereCHF AND hasOrthopnea;\n",
    "\n",
    "define final BlackSevereCHFPatient:\n",
    "    where SevereCHF AND BlackRace;\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
